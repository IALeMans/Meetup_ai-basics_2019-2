{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "1_ANN_supervised_classifier_ann.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IALeMans/Meetup_ai-basics_2019-2/blob/master/1_ANN_supervised_classifier_ann_WR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlRiDQEoofla",
        "colab_type": "text"
      },
      "source": [
        "# ARTIFICIAL NEURAL NETWORK\n",
        "### Part 1 - Data Preprocessing > done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k11zcTBNpA_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c310b599-0e6b-4503-e57e-23866fb4082e"
      },
      "source": [
        "!pip install wget\n",
        "import wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=0dabde0aa594129b4b225d19739f1a9823d66926764de4fa1bd40bdb7510bb58\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te-76zNIoflp",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 - Now let's make the ANN!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRaew0mPofl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad9cd668-0c98-4e92-dad1-2ddf02c45b2b"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2jgOLGiofmd",
        "colab_type": "text"
      },
      "source": [
        "## get back datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-uZoRWcofml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "from numpy import array,matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MzVGvN8ofm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://github.com/IALeMans/Meetup_ai-basics_2019-2/raw/master/datasets.p'\n",
        "filename = wget.download(url)\n",
        "\n",
        "datasets_name = ['X_train', 'X_test', 'y_train', 'y_test']\n",
        "f = open(filename, 'rb')\n",
        "dataset = {}\n",
        "for dataset_name in datasets_name:\n",
        "    dataset[dataset_name]=(pickle.load(f))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAZZovJRofnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "a76560af-feb6-4726-c06f-04905b32110a"
      },
      "source": [
        "print(dataset['X_train'].shape)\n",
        "print(dataset['X_test'].shape)\n",
        "print(dataset['y_train'].shape)\n",
        "print(dataset['y_test'].shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 11)\n",
            "(2000, 11)\n",
            "(8000,)\n",
            "(2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZLZBscjofne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "8cf3c519-a459-4365-a712-456c57d93071"
      },
      "source": [
        "dataset['X_train'][:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5698444 ,  1.74309049,  0.16958176, -1.09168714, -0.46460796,\n",
              "         0.00666099, -1.21571749,  0.8095029 ,  0.64259497, -1.03227043,\n",
              "         1.10643166],\n",
              "       [ 1.75486502, -0.57369368, -2.30455945,  0.91601335,  0.30102557,\n",
              "        -1.37744033, -0.00631193, -0.92159124,  0.64259497,  0.9687384 ,\n",
              "        -0.74866447],\n",
              "       [-0.5698444 , -0.57369368, -1.19119591, -1.09168714, -0.94312892,\n",
              "        -1.031415  ,  0.57993469, -0.92159124,  0.64259497, -1.03227043,\n",
              "         1.48533467],\n",
              "       [-0.5698444 ,  1.74309049,  0.03556578,  0.91601335,  0.10961719,\n",
              "         0.00666099,  0.47312769, -0.92159124,  0.64259497, -1.03227043,\n",
              "         1.27652776],\n",
              "       [-0.5698444 ,  1.74309049,  2.05611444, -1.09168714,  1.73658844,\n",
              "         1.04473698,  0.8101927 ,  0.8095029 ,  0.64259497,  0.9687384 ,\n",
              "         0.55837842]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r8f5y7Gofnw",
        "colab_type": "text"
      },
      "source": [
        "## let's build your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bos3EW5Pofn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "daa56ea4-3adb-44e3-a12d-4e01f781e24e"
      },
      "source": [
        "# Initialising the ANN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux2S-CJvofoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ede37082-a8e5-4c38-e542-db4c5d449f1d"
      },
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "# classifier.add(Dropout(p = 0.1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLYjqj3pofoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "# classifier.add(Dropout(p = 0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Frk5fdLofok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Enp-ZAofo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9561c493-e2ed-4d6d-8d3e-f2469cb24607"
      },
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lP_oby1ofpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "20c822be-1483-4c42-dd84-b8bccd2f4e4a"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HysdaZ6jofpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b29b01c7-b829-41d1-ab20-b9725de9fe04"
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history = classifier.fit(dataset['X_train'], dataset['y_train'], validation_split=0.25, epochs=100, batch_size=100, verbose=1)\n",
        "#history = classifier.fit(dataset['X_train'], dataset['y_train'], epochs=3, batch_size=16, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 6000 samples, validate on 2000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "6000/6000 [==============================] - 5s 780us/step - loss: 0.6812 - acc: 0.7900 - val_loss: 0.6644 - val_acc: 0.7995\n",
            "Epoch 2/100\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.6321 - acc: 0.7948 - val_loss: 0.5842 - val_acc: 0.7995\n",
            "Epoch 3/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.5310 - acc: 0.7948 - val_loss: 0.4813 - val_acc: 0.7995\n",
            "Epoch 4/100\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4577 - acc: 0.7948 - val_loss: 0.4446 - val_acc: 0.7995\n",
            "Epoch 5/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.4344 - acc: 0.7948 - val_loss: 0.4349 - val_acc: 0.7995\n",
            "Epoch 6/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.4260 - acc: 0.8020 - val_loss: 0.4311 - val_acc: 0.8145\n",
            "Epoch 7/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4216 - acc: 0.8135 - val_loss: 0.4276 - val_acc: 0.8115\n",
            "Epoch 8/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.4177 - acc: 0.8173 - val_loss: 0.4243 - val_acc: 0.8180\n",
            "Epoch 9/100\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4143 - acc: 0.8197 - val_loss: 0.4215 - val_acc: 0.8220\n",
            "Epoch 10/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4115 - acc: 0.8207 - val_loss: 0.4180 - val_acc: 0.8235\n",
            "Epoch 11/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.4083 - acc: 0.8192 - val_loss: 0.4146 - val_acc: 0.8270\n",
            "Epoch 12/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4054 - acc: 0.8202 - val_loss: 0.4120 - val_acc: 0.8275\n",
            "Epoch 13/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4025 - acc: 0.8230 - val_loss: 0.4088 - val_acc: 0.8290\n",
            "Epoch 14/100\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.3999 - acc: 0.8232 - val_loss: 0.4065 - val_acc: 0.8260\n",
            "Epoch 15/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3970 - acc: 0.8238 - val_loss: 0.4032 - val_acc: 0.8255\n",
            "Epoch 16/100\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.3947 - acc: 0.8245 - val_loss: 0.4012 - val_acc: 0.8265\n",
            "Epoch 17/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3923 - acc: 0.8255 - val_loss: 0.3988 - val_acc: 0.8280\n",
            "Epoch 18/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3902 - acc: 0.8268 - val_loss: 0.3967 - val_acc: 0.8275\n",
            "Epoch 19/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3880 - acc: 0.8287 - val_loss: 0.3951 - val_acc: 0.8275\n",
            "Epoch 20/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3863 - acc: 0.8278 - val_loss: 0.3929 - val_acc: 0.8270\n",
            "Epoch 21/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3844 - acc: 0.8290 - val_loss: 0.3913 - val_acc: 0.8285\n",
            "Epoch 22/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3824 - acc: 0.8292 - val_loss: 0.3896 - val_acc: 0.8290\n",
            "Epoch 23/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3810 - acc: 0.8293 - val_loss: 0.3878 - val_acc: 0.8295\n",
            "Epoch 24/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3795 - acc: 0.8312 - val_loss: 0.3865 - val_acc: 0.8275\n",
            "Epoch 25/100\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.3779 - acc: 0.8325 - val_loss: 0.3847 - val_acc: 0.8300\n",
            "Epoch 26/100\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.3768 - acc: 0.8308 - val_loss: 0.3842 - val_acc: 0.8300\n",
            "Epoch 27/100\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.3757 - acc: 0.8320 - val_loss: 0.3824 - val_acc: 0.8320\n",
            "Epoch 28/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3740 - acc: 0.8337 - val_loss: 0.3825 - val_acc: 0.8290\n",
            "Epoch 29/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3732 - acc: 0.8328 - val_loss: 0.3814 - val_acc: 0.8270\n",
            "Epoch 30/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3721 - acc: 0.8327 - val_loss: 0.3800 - val_acc: 0.8305\n",
            "Epoch 31/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3711 - acc: 0.8427 - val_loss: 0.3787 - val_acc: 0.8380\n",
            "Epoch 32/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3702 - acc: 0.8423 - val_loss: 0.3784 - val_acc: 0.8375\n",
            "Epoch 33/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3693 - acc: 0.8433 - val_loss: 0.3781 - val_acc: 0.8380\n",
            "Epoch 34/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3683 - acc: 0.8442 - val_loss: 0.3774 - val_acc: 0.8390\n",
            "Epoch 35/100\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.3673 - acc: 0.8467 - val_loss: 0.3758 - val_acc: 0.8415\n",
            "Epoch 36/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3667 - acc: 0.8468 - val_loss: 0.3766 - val_acc: 0.8415\n",
            "Epoch 37/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3655 - acc: 0.8473 - val_loss: 0.3742 - val_acc: 0.8430\n",
            "Epoch 38/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3649 - acc: 0.8458 - val_loss: 0.3744 - val_acc: 0.8405\n",
            "Epoch 39/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3644 - acc: 0.8480 - val_loss: 0.3730 - val_acc: 0.8450\n",
            "Epoch 40/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3630 - acc: 0.8497 - val_loss: 0.3726 - val_acc: 0.8415\n",
            "Epoch 41/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3622 - acc: 0.8495 - val_loss: 0.3719 - val_acc: 0.8450\n",
            "Epoch 42/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3619 - acc: 0.8475 - val_loss: 0.3713 - val_acc: 0.8440\n",
            "Epoch 43/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3616 - acc: 0.8490 - val_loss: 0.3717 - val_acc: 0.8430\n",
            "Epoch 44/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3606 - acc: 0.8483 - val_loss: 0.3701 - val_acc: 0.8450\n",
            "Epoch 45/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3598 - acc: 0.8508 - val_loss: 0.3710 - val_acc: 0.8455\n",
            "Epoch 46/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3590 - acc: 0.8520 - val_loss: 0.3685 - val_acc: 0.8465\n",
            "Epoch 47/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3586 - acc: 0.8507 - val_loss: 0.3691 - val_acc: 0.8465\n",
            "Epoch 48/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3572 - acc: 0.8522 - val_loss: 0.3682 - val_acc: 0.8490\n",
            "Epoch 49/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3570 - acc: 0.8522 - val_loss: 0.3681 - val_acc: 0.8495\n",
            "Epoch 50/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3559 - acc: 0.8538 - val_loss: 0.3669 - val_acc: 0.8500\n",
            "Epoch 51/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3557 - acc: 0.8543 - val_loss: 0.3678 - val_acc: 0.8465\n",
            "Epoch 52/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3548 - acc: 0.8533 - val_loss: 0.3666 - val_acc: 0.8500\n",
            "Epoch 53/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3545 - acc: 0.8550 - val_loss: 0.3657 - val_acc: 0.8525\n",
            "Epoch 54/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3532 - acc: 0.8535 - val_loss: 0.3660 - val_acc: 0.8510\n",
            "Epoch 55/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3523 - acc: 0.8550 - val_loss: 0.3664 - val_acc: 0.8515\n",
            "Epoch 56/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3524 - acc: 0.8545 - val_loss: 0.3655 - val_acc: 0.8550\n",
            "Epoch 57/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3515 - acc: 0.8562 - val_loss: 0.3652 - val_acc: 0.8510\n",
            "Epoch 58/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3514 - acc: 0.8553 - val_loss: 0.3647 - val_acc: 0.8535\n",
            "Epoch 59/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3502 - acc: 0.8585 - val_loss: 0.3639 - val_acc: 0.8520\n",
            "Epoch 60/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3501 - acc: 0.8565 - val_loss: 0.3646 - val_acc: 0.8550\n",
            "Epoch 61/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3494 - acc: 0.8555 - val_loss: 0.3633 - val_acc: 0.8525\n",
            "Epoch 62/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3487 - acc: 0.8573 - val_loss: 0.3631 - val_acc: 0.8525\n",
            "Epoch 63/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3488 - acc: 0.8573 - val_loss: 0.3637 - val_acc: 0.8525\n",
            "Epoch 64/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3484 - acc: 0.8562 - val_loss: 0.3624 - val_acc: 0.8565\n",
            "Epoch 65/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3478 - acc: 0.8575 - val_loss: 0.3652 - val_acc: 0.8515\n",
            "Epoch 66/100\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.3490 - acc: 0.8568 - val_loss: 0.3633 - val_acc: 0.8500\n",
            "Epoch 67/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3475 - acc: 0.8558 - val_loss: 0.3625 - val_acc: 0.8520\n",
            "Epoch 68/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3478 - acc: 0.8590 - val_loss: 0.3619 - val_acc: 0.8540\n",
            "Epoch 69/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3466 - acc: 0.8572 - val_loss: 0.3621 - val_acc: 0.8530\n",
            "Epoch 70/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3464 - acc: 0.8608 - val_loss: 0.3611 - val_acc: 0.8595\n",
            "Epoch 71/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3456 - acc: 0.8583 - val_loss: 0.3612 - val_acc: 0.8540\n",
            "Epoch 72/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3448 - acc: 0.8597 - val_loss: 0.3629 - val_acc: 0.8490\n",
            "Epoch 73/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3455 - acc: 0.8590 - val_loss: 0.3607 - val_acc: 0.8560\n",
            "Epoch 74/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3448 - acc: 0.8600 - val_loss: 0.3618 - val_acc: 0.8565\n",
            "Epoch 75/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3446 - acc: 0.8592 - val_loss: 0.3615 - val_acc: 0.8540\n",
            "Epoch 76/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3438 - acc: 0.8607 - val_loss: 0.3610 - val_acc: 0.8575\n",
            "Epoch 77/100\n",
            "6000/6000 [==============================] - 0s 59us/step - loss: 0.3446 - acc: 0.8608 - val_loss: 0.3601 - val_acc: 0.8585\n",
            "Epoch 78/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3432 - acc: 0.8607 - val_loss: 0.3606 - val_acc: 0.8570\n",
            "Epoch 79/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3437 - acc: 0.8605 - val_loss: 0.3590 - val_acc: 0.8590\n",
            "Epoch 80/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3427 - acc: 0.8600 - val_loss: 0.3604 - val_acc: 0.8545\n",
            "Epoch 81/100\n",
            "6000/6000 [==============================] - 0s 57us/step - loss: 0.3425 - acc: 0.8618 - val_loss: 0.3605 - val_acc: 0.8520\n",
            "Epoch 82/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3427 - acc: 0.8603 - val_loss: 0.3594 - val_acc: 0.8570\n",
            "Epoch 83/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3422 - acc: 0.8598 - val_loss: 0.3593 - val_acc: 0.8575\n",
            "Epoch 84/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3423 - acc: 0.8613 - val_loss: 0.3588 - val_acc: 0.8575\n",
            "Epoch 85/100\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.3425 - acc: 0.8608 - val_loss: 0.3598 - val_acc: 0.8555\n",
            "Epoch 86/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3426 - acc: 0.8602 - val_loss: 0.3585 - val_acc: 0.8585\n",
            "Epoch 87/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3416 - acc: 0.8607 - val_loss: 0.3581 - val_acc: 0.8585\n",
            "Epoch 88/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3409 - acc: 0.8598 - val_loss: 0.3594 - val_acc: 0.8570\n",
            "Epoch 89/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3410 - acc: 0.8622 - val_loss: 0.3584 - val_acc: 0.8600\n",
            "Epoch 90/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3406 - acc: 0.8615 - val_loss: 0.3585 - val_acc: 0.8570\n",
            "Epoch 91/100\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.3408 - acc: 0.8610 - val_loss: 0.3582 - val_acc: 0.8590\n",
            "Epoch 92/100\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.3402 - acc: 0.8600 - val_loss: 0.3581 - val_acc: 0.8580\n",
            "Epoch 93/100\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.3399 - acc: 0.8632 - val_loss: 0.3589 - val_acc: 0.8550\n",
            "Epoch 94/100\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.3399 - acc: 0.8612 - val_loss: 0.3577 - val_acc: 0.8575\n",
            "Epoch 95/100\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.3399 - acc: 0.8623 - val_loss: 0.3582 - val_acc: 0.8555\n",
            "Epoch 96/100\n",
            "6000/6000 [==============================] - 0s 55us/step - loss: 0.3399 - acc: 0.8602 - val_loss: 0.3579 - val_acc: 0.8585\n",
            "Epoch 97/100\n",
            "6000/6000 [==============================] - 0s 56us/step - loss: 0.3396 - acc: 0.8632 - val_loss: 0.3583 - val_acc: 0.8575\n",
            "Epoch 98/100\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.3394 - acc: 0.8615 - val_loss: 0.3585 - val_acc: 0.8585\n",
            "Epoch 99/100\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.3404 - acc: 0.8600 - val_loss: 0.3568 - val_acc: 0.8580\n",
            "Epoch 100/100\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.3394 - acc: 0.8615 - val_loss: 0.3575 - val_acc: 0.8575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCejpynvofph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "0acc7b9f-5fa7-4ab1-9274-efb867a9621c"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGPMiCwsjDHGjOj/B1e4R1JsH3kqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfOsZQj7p84V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKLKZ3F7ofpu",
        "colab_type": "text"
      },
      "source": [
        "# Part 3 - Making predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNtzGFqXofpy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "df937606-1949-4078-a7b9-fc2b949b8bbc"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(dataset['X_test'])\n",
        "\n",
        "# ground truth\n",
        "print('\\nground truth')\n",
        "print(dataset['y_test'][:5])\n",
        "\n",
        "# predicted values\n",
        "print('\\npredictions')\n",
        "print(y_pred[:5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ground truth\n",
            "[0 1 0 0 0]\n",
            "\n",
            "predictions\n",
            "[[0.29356053]\n",
            " [0.3318918 ]\n",
            " [0.14023453]\n",
            " [0.08690995]\n",
            " [0.05638936]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8leOi2ZofqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8f17f358-3056-40a2-8a0d-9843650ef009"
      },
      "source": [
        "# from percent to class\n",
        "y_pred_class = (y_pred > 0.50)\n",
        "print(y_pred_class[:5])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQTYMTZIofqc",
        "colab_type": "text"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RDw0HiJofqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred_class = (y_pred > 0.50)\n",
        "\n",
        "labels = ['stay', 'exit']\n",
        "cm = confusion_matrix(dataset['y_test'], y_pred_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmrpLoNwofqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5497a22c-9db9-4877-ef73-10cb70e97e04"
      },
      "source": [
        "cm"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1514,   81],\n",
              "       [ 204,  201]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqa7TQAZofq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d95926d3-13b8-4eae-e144-e82737d64ec9"
      },
      "source": [
        "labels = ['stay', 'exit']\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEQCAYAAAA04CbtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH6ZJREFUeJzt3XmcXmV99/HPlwTZIUAghRAIFdSi\nrRYRqZSWRVbR0FYRFIkUS7XWlqJVVF4Ft+cBbUtdKjUUBAFZ5KkVFYU0Ql0qS9jCWpJqMQmBkAQi\nO2Hm+/xxroE7wyznntxzZu7J9/16ndecc53rnHPd22+u5SyyTURE1LPBWBcgIqKbJGhGRLQhQTMi\nog0JmhERbUjQjIhoQ4JmREQbEjQ7RNImkr4rabWkb63Dft4t6dpOlm2sSNpP0n+Pwn7bfq8lXS/p\nfZ0uS79jvFfST0dx/z+QNLtl+bOSVkh6SNLOkp6QNGm0jh+VyWNdgKZJehdwCvAq4HHgduBzttf1\ny/52YBqwre3nR7oT25cAl6xjWUadJAO72140WB7bPwFeOQqHH/K9lnQGsJvt40bh2GPG9uF985J2\nBj4M7GJ7eUnefEwKtp5Zr2qakk4B/gn4P1Q/up2BrwKzOrD7XYD71yVgTiSSRvMfct7r6ru7siVg\njtgof1YTj+31YgK2Ap4A3jFEno2oguqDZfonYKOybn9gCdV/9+XAMuCEsu5TwHPAmnKME4EzgItb\n9j0TMDC5LL8X+AVVbfeXwLtb0n/ast2bgJuB1eXvm1rWXQ98BvhZ2c+1wNRBXltf+T/aUv6jgCOA\n+4FVwCda8u8N/Bx4rOT9CvCysu7H5bU8WV7vO1v2/zHgIeCivrSyzcvLMfYsyzsCjwD7D1Le3yqv\n7zHgbuBtg73X/bY7rN/6O+q8V8A+wH+V490xWLlK3hnAv5XyrwS+Mshn90VgMfBr4BZgv37v7/yy\n7mHgH0v6xsDFZb+Plc98WstreB/wZuBpoLe8xgt46fdrK+C88tktBT4LTGop58+As8txPjvWv89u\nmsa8AI290OrH9Hzfl2qQPJ8GbgC2B7YrP6LPlHX7l+0/DWxIFWyeArYu689g7SDZf/mFLzWwWfmx\nvLKs2wF4dZl/4YcHbAM8CrynbHdsWd62rL8e+B/gFcAmZfnMQV5bX/n/rpT/z8qP/pvAFsCryw9x\n15L/9VSBZHIp+73AyS37M1UTuP/+z6L657MJLUGz5Pkz4B5gU+Aa4O8HKeuGwCLgE8DLgAOpAt0r\nB3pvB9j+JeuHeq+A6VTB4wiq1tfBZXm7AfY9iSqonl0+x42B3+//2ZXl44Bty3v4Yap/JhuXdT8H\n3lPmNwf2KfN/Dny3vEeTyuewZctreF/L+9363s5k7aD5beBrpYzbAzcBf95SzueBD5WybTLWv89u\nmtan5vm2wAoP3aR7N/Bp28ttP0JVq3lPy/o1Zf0a21dT/ZcfaZ9dL/AaSZvYXmb77gHyvAVYaPsi\n28/bvhS4D3hrS56v277f9tPAFcDrhjjmGqr+2zXAZcBU4Iu2Hy/Hvwd4LYDtW2zfUI77v1Q/wD+s\n8ZpOt/1sKc9abJ9LFQxvpPpH8clB9rMPVSA50/Zztn8EfI/qn8a6GOy9Og642vbVtnttz6WqBR4x\nwD72pqol/63tJ20/40H6w21fbHtleQ//geqfSd/3ZQ2wm6Sptp+wfUNL+rZU/5B6yufw63ZepKRp\npewnlzIupwryx7Rke9D2l0vZXvJZxeDWp6C5Epg6TP/NjsADLcsPlLQX9tEv6D7FCDrfbT9J1aR9\nP7BM0vclvapGefrKNL1l+aE2yrPSdk+Z7/uhPNyy/um+7SW9QtL3ysjsr6n6gacOsW+AR2w/M0ye\nc4HXAF+2/ewgeXYEFtvubUnr/7pHYrD3ahfgHZIe65uA36cK7P3NAB4Y5p8vAJI+IuneMsr/GFWT\nue89PJGq1nufpJslHVnSL6KqhV8m6UFJn5e0YZuvcxeq2vqyltfzNaoaZ5/Fbe4zivUpaP4ceJaq\nH28wD1J94frsXNJG4kmqJlaf32hdafsa2wdT/TDvowomw5Wnr0xLR1imdpxDVa7dbW9J1VTWMNsM\necssSZtT9ROfB5whaZtBsj4IzJDU+v1s53W3e+uuxcBFtqe0TJvZPnOQvDsPN3giaT+q/uOjqbpw\nplD1SwvA9kLbx1IFsrOAKyVtVloxn7K9B1V/9pHA8SN4Pc9S9dn2vZ4tbb+6JU9ubzZC603QtL2a\nqj/vnyUdJWlTSRtKOlzS50u2S4HTJG0naWrJf/EID3k78Afl/LmtgI/3rZA0TdIsSZtRfbmfoGra\n9nc18ApJ75I0WdI7gT2omqqjbQuqftcnSi34A/3WPwz8Zpv7/CIw3/b7gO8D/zJIvhupaoIfLZ/R\n/lRdEpfVPM7DwMx+QXcoFwNvlXSopEmSNpa0v6SdBsh7E9XgypmSNit59x0g3xZU/YaPAJMl/R2w\nZd9KScdJ2q7Uph8ryb2SDpD02+V8y19TNdcH+m4MyvYyqoGuf5C0paQNJL1c0nDdK1HDehM0AUq/\n0inAaVRf5sXAXwL/XrJ8lqovawFwJ3BrSRvJseYCl5d93cLagW6DUo4HqUaU/5CXBiVsr6SqaXyY\nqnvho8CRtleMpExt+gjwLqoBmHOpXkurM4ALS/Pv6OF2JmkW1WBc3+s8BdhT0rv757X9HFWQPBxY\nQXVa2PG276tZ9r4T3ldKunW4zLYXU5129gle/F78LQP8Pkr3xluB3YBfUZ0x8M4BdnsN8EOqMxMe\nAJ5h7SbxYcDdkp6g+mdyTOlb/A3gSqqAeS/wn1RN9nYdTzWIdg/V4OGVDNzdEG2SnVr6eCHpZGCO\n7afGuizRGZL+y/abJM2kOl3sm2NcpFhH61VNswuczNr9oNHlbL+pzM6kqrlHl0vQHCOlP+z7ku6Q\ndJek06lGja+TdF3Jc46k+ZLulvSpknagpH9v2c/Bkr49Nq9i/VT6I2+SdLukr0naRdJCSVNL/+FP\nJB1S8j5RNjsT2K9s8zdjV/pYV2mejxFJfwIcZvvPyvJWVCdN79XXZylpG9uryqDAPOCvqPpa76W6\nuuQRSd8ELrX93TF5IesZSb8FfB74Y9trJH2V6oKIlwGHUg0U7Wb7z0v+J2xvXgazPmL7yEF2HV0i\nNc2xcydwsKSzJO1XRvf7O7oMZNxGdcXOHq7+y10EHCdpCvB7wA8aK3UcRHWVzs2Sbi/Lv2n7X6lG\nx99PNYgWE1Qu1B8jtu+XtCfVlRuflTSvdb2kXal+fG+w/aikC6gu2QP4OtWlds8A36pzonV0jIAL\nbX98rURpU6DvFKXNqc46iAkoNc0xImlH4CnbFwNfAPak+qFtUbJsSXWC/OpyWdwLtwWz3XdDkdOo\nAmg0Zx7wdknbQ9WFImkXqhPUL6E6t3egCxVaP9voYqlpjp3fBr4gqZfqBOYPUDW1fyjpQdsHSLqN\n6qqcxVR3pWl1CdUNJe5tstDrO9v3SDoNuLacPL+G6pzTNwD72u6R9CeSTrDd+g9tAdAj6Q7gAttn\nN1/66IQMBHUpSV8BbrN93liXJWJ9kqDZhSTdQtV0P3iIm15ExChI0IyIaEMGgiIi2pCgGRHRhgTN\ncU7SSWNdhqgvn9fEl6A5/uVH2F3yeU1wCZoREW2YEKPnU7eZ5Jkz2n2MSnd4ZGUP2207aayL0XH3\nL5iYd8Bbw7NsyEZjXYxR8TiPrrC93brs49ADNvPKVT3D5rtlwbPX2D5sXY41WibEFUEzZ2zITdfM\nGOtiRBsO3XGoh2bGePQfvrL/Q/7atnJVDzdds/Ow+SbtsHC4h/iNmQkRNCOiOxjobe+RR+NOgmZE\nNMaYNR6+eT6eJWhGRKNS04yIqMmYni4ffE7QjIhG9ZKgGRFRi4GeBM2IiPpS04yIqMnAmvRpRkTU\nY5zmeUREbYae7o6ZCZoR0ZzqiqDulqAZEQ0SPWisC7FOcmu4iGhMNRCkYac6JJ0vabmkuwZY92FJ\nljS1LEvSlyQtkrRA0p4teWdLWlim2cMdN0EzIhpTnaepYaeaLgBecvs4STOAQ4BftSQfDuxeppOA\nc0rebYDTgTcCewOnS9p6qIMmaEZEo3qtYac6bP8YWDXAqrOBj8Jaw/SzgG+4cgMwRdIOwKHAXNur\nbD8KzGWAQNwqfZoR0Zi+muZokTQLWGr7Dmmt40wHFrcsLylpg6UPKkEzIhpjRE+9Bu5USfNblufY\nnjPUBpI2BT5B1TQfNQmaEdGoms3vFbb3anPXLwd2BfpqmTsBt0raG1gKtD7eYaeSthTYv1/69UMd\nJH2aEdEYI57zpGGnEe3bvtP29rZn2p5J1dTe0/ZDwFXA8WUUfR9gte1lwDXAIZK2LgNAh5S0QaWm\nGRGNqU5u70xdTdKlVLXEqZKWAKfbPm+Q7FcDRwCLgKeAEwBsr5L0GeDmku/TtgcaXHpBgmZENKpT\nA0G2jx1m/cyWeQMfHCTf+cD5dY+boBkRjbFFj7u7VzBBMyIa1dvll1EmaEZEY6qBoO4OO91d+ojo\nKp0cCBorCZoR0aiempdJjlcJmhHRmDauCBq3EjQjolG9GT2PiKinumFHgmZERC1GrBnhZZLjRYJm\nRDTGJie3R0TUp5zcHhFRl0lNMyKiLRkIioioydR/BtB4laAZEY2pHuHb3WGnu0sfEV2mrUf0jksJ\nmhHRGJMrgiIi2pKaZkRETbZS04yIqKsaCMpllBERNeUZQRERtVUDQd3dp9ndIT8iuk4PGww71SHp\nfEnLJd3VkvYFSfdJWiDp25KmtKz7uKRFkv5b0qEt6YeVtEWSTh3uuAmaEdGYviuChptqugA4rF/a\nXOA1tn8HuB/4OICkPYBjgFeXbb4qaZKkScA/A4cDewDHlryDStCMiEb1ssGwUx22fwys6pd2re3n\ny+INwE5lfhZwme1nbf8SWATsXaZFtn9h+zngspJ3UOnTjIjG2LCmt1ZQnCppfsvyHNtz2jzcnwKX\nl/npVEG0z5KSBrC4X/obh9ppgmZENKZqntcKmits7zXS40j6JPA8cMlI9zGYBM2IaNRoXxEk6b3A\nkcBBtl2SlwIzWrLtVNIYIn1AjfZpSjpZ0qZNHjMixo++U446NBD0EpIOAz4KvM32Uy2rrgKOkbSR\npF2B3YGbgJuB3SXtKullVINFVw11jKZrmicDFwNPDZcxIiaizl1GKelSYH+q/s8lwOlUo+UbAXMl\nAdxg+/2275Z0BXAPVbP9g7Z7yn7+ErgGmAScb/vuoY47akFT0mbAFVTV3UnAt4AdgeskrbB9gKRz\ngDcAmwBX2j5d0oHAX9k+quznYOAvbP/RaJU1IprTqWcE2T52gOTzhsj/OeBzA6RfDVxd97ijWdM8\nDHjQ9lsAJG0FnAAcYHtFyfNJ26vKuVLzJP0OcB3VOVTb2X6kbHP+KJYzIhpSjZ5397Xno9mneSdw\nsKSzJO1ne/UAeY6WdCtwG9VJp3uUjtuLgOPK2fy/B/yg/4aSTpI0X9L8R1b2jOLLiIhO6fDJ7WNi\n1Gqatu+XtCdwBPBZSfNa15fO2I8Ab7D9qKQLgI3L6q8D3wWeAb7VcrJq6/7nAHMA9nrtxu6/PiLG\npzzCdxCSdgRW2b5Y0mPA+4DHgS2AFcCWwJPAaknTqC5juh7A9oOSHgROA948WmWMiGZNhBt2jGaf\n5m8DX5DUC6wBPkDV1P6hpAfLQNBtwH1UZ+T/rN/2lwDb2b53FMsYEQ3LTYgHYfsaqmH8VvOBL7fk\nee8Qu/h94NzOlywixootnk/Q7DxJt1A13T881mWJiM5K83wU2H79WJchIjovfZoREW1K0IyIqKnv\nPM1ulqAZEY3KeZoRETXZ8Hy9mxCPWwmaEdGoNM8jImpKn2ZERJucoBkRUV8GgiIiarLTpxkR0QbR\nk9HziIj60qcZEVFTrj2PiGiHq37NbtbdnQsR0XV60bBTHZLOl7Rc0l0tadtImitpYfm7dUmXpC9J\nWiRpQXkUT982s0v+hZJmD3fcBM2IaIzLQNBwU00XUD31ttWpwDzbuwPzyjJUj9PZvUwnAedAFWSp\nnpf+RmBv4PS+QDuYBM2IaJQ9/FRvP/4xsKpf8izgwjJ/IXBUS/o3XLkBmCJpB+BQYK7tVbYfBeby\n0kC8lvRpRkSjao6eT5U0v2V5TnkC7XCm2V5W5h8CppX56VTPIuuzpKQNlj6oBM2IaExVk6wVNFfY\n3mvdjmVL6viwU5rnEdGoXmvYaR08XJrdlL/LS/pSYEZLvp1K2mDpg0rQjIhGdapPcxBXAX0j4LOB\n77SkH19G0fcBVpdm/DXAIZK2LgNAh/DSp+iuJc3ziGiMEb0duoxS0qXA/lT9n0uoRsHPBK6QdCLw\nAHB0yX41cASwCHgKOAHA9ipJnwFuLvk+bbv/4NJaEjQjolGd6mS0fewgqw4aIK+BDw6yn/OB8+se\nN0EzIppTfyBo3ErQjIhmdflllAmaEdGo1DQjImoy0NuboBkRUY+B1DQjIurr9lvDJWhGRLMSNCMi\n6lIGgiIi2pKaZkRETQZn9Dwioh0JmhER9aV5HhHRhgTNiIiacnJ7RER71puT2yVtZPvZ0SxMRKwH\nunz0fNhbKEvaW9KdwMKy/FpJXx71kkXEhCQPP41nde47/yXgSGAlgO07gANGs1ARMUG55jSO1Wme\nb2D7AWmtKnXPKJUnIiY0rRcDQYsl7Q1Y0iTgQ8D9o1usiJiwxnlNcjh1guYHqJroOwMPA/9R0iIi\n2tc71gVYN8MGTdvLgWMaKEtETHQdPE9T0t8A7yt7vZPqsbw7AJcB2wK3AO+x/ZykjYBvAK+nGp95\np+3/Hclxhw2aks5lgAq17ZNGcsCIWL91YnRc0nTgr4A9bD8t6Qqqyt0RwNm2L5P0L8CJwDnl76O2\nd5N0DHAW8M6RHLvO6Pl/APPK9DNgeyDna0bEyHRu9HwysImkycCmwDLgQODKsv5C4KgyP6ssU9Yf\npH6j2+0cdEi2L29dlnQR8NORHCwiohNsL5X098CvgKeBa6ma44/Zfr5kWwJML/PTgcVl2+clraZq\nwq9o99gjuYxyV2DaCLYbNQvv24q3vPHIsS5GtGHyjLEuQbTtV53ZTc3m+VRJ81uW59ie88I+pK2p\nao+7Ao8B3wIO60wJh1anT/NRXqwwbwCsAk4dzUJFxARl6l5GucL2XkOsfzPwS9uPAEj6N2BfYIqk\nyaW2uROwtORfCswAlpTm/FaUC3baNWSfZmnzvxbYrkxb2/5N21eM5GARER3q0/wVsI+kTUucOgi4\nB7gOeHvJMxv4Tpm/qixT1v/IHtmtQ4YMmmWnV9vuKVOXn5YaEWOtE9ee276RakDnVqrTjTYA5gAf\nA06RtIiqz/K8ssl5wLYl/RTWobVcp0/zdkm/a/u2kR4kIuIFHap62T4dOL1f8i+AvQfI+wzwjk4c\nd9Cg2dIv8LvAzZL+B3iS6gEftr1nJwoQEeuZLm+vDlXTvAnYE3hbQ2WJiAmuG279NpyhgqYAbP9P\nQ2WJiPVBl9+EeKiguZ2kUwZbafsfR6E8ETHBTeSa5iRgc7r9IcURMb5M4KC5zPanGytJREx860Of\nZkRER03goHlQY6WIiPWGuvwmxINeEWR7VZMFiYjoBiO5y1FExMhN4OZ5RERnTfCBoIiIzkvQjIho\nQ4JmREQ9ovtHzxM0I6I56dOMiGhTgmZERBsSNCMi6kvzPCKiHQmaERE1OaPnERHtSU0zIqK+bu/T\nHPK55xERHecaUw2Spki6UtJ9ku6V9HuStpE0V9LC8nfrkleSviRpkaQFkkb8NN0EzYhoTp2AWb8m\n+kXgh7ZfBbwWuBc4FZhne3dgXlkGOBzYvUwnAeeM9CUkaEZEY8SLj/Edahp2P9JWwB8A5wHYfs72\nY8As4MKS7ULgqDI/C/iGKzcAUyTtMJLXkKAZEY2qGTSnSprfMp3Ubze7Ao8AX5d0m6R/lbQZMM32\nspLnIWBamZ8OLG7ZfklJa1sGgiKiWfWa3yts7zXE+snAnsCHbN8o6Yu82BSvDmNb6vywU2qaEdGs\nzvRpLgGW2L6xLF9JFUQf7mt2l7/Ly/qlwIyW7XcqaW1L0IyI5tRomtepG9p+CFgs6ZUl6SDgHuAq\nYHZJmw18p8xfBRxfRtH3AVa3NOPbkuZ5RDSrcw3mDwGXSHoZ8AvgBKqK4BWSTgQeAI4uea8GjgAW\nAU+VvCOSoBkRjerUZZS2bwcG6vd8yePHbRv4YCeOm6AZEY3q9iuCEjQjojntnbw+LiVoRkSzEjQj\nIurpuyKomyVoRkSj1NvdUTNBMyKakz7NiIj2pHkeEdGOBM2IiPpS04yIaEeCZkRETXkaZUREfTlP\nMyKiXe7uqJmgGRGNSk0zIqKuCXBy+7i7c7uk/yp/Z0p611iXJyI6S73DT+PZuAuatt9UZmcCCZoR\nE0yCZg2SjpN0k6TbJX1N0i6SFkqaKmkDST+RdEjJ+0TZ7Exgv7LN3zRRzogYZaYaCBpuGsdGvU9T\n0m8B7wT2tb1G0leBPwTOAs4BbgLusX1tv01PBT5i+8hB9nsScBLAxpO2GK3iR0SHZSBoeAcBrwdu\nlgSwCbDc9hmS3gG8H3hduzu1PQeYA7DVRtO6/GOIWI90+a+1iaAp4ELbH18rUdqU6tnDAJsDjzdQ\nlogYQxPh5PYm+jTnAW+XtD2ApG0k7ULVPL8E+Dvg3AG2exxIuztiIrFR7/BTXZImSbpN0vfK8q6S\nbpS0SNLl5fG+SNqoLC8q62eO9CWMetC0fQ9wGnCtpAXAXKqR8TcAZ9m+BHhOUv/nEC8AeiTdkYGg\niAnENab6/hq4t2X5LOBs27sBjwInlvQTgUdL+tkl34g0cnK77cuBy/sl79Oy/o9b5jcvf9cABzZR\nvohoTqea55J2At4CfA44RdWgyYG8eKrihcAZVAPOs8o8wJXAVySpPA+9LePuPM2ImMAM9Hr4CaZK\nmt8ynTTA3v4J+CjQd2bntsBjtp8vy0uA6WV+OrAYoKxfXfK3LZdRRkSz6tXtVtjea7CVko6kOgvn\nFkn7d6hktSRoRkSjOtQ83xd4m6QjgI2BLYEvAlMkTS61yZ2ApSX/UmAGsETSZGArYOVIDpzmeUQ0\nqhOj57Y/bnsn2zOBY4Af2X43cB3w9pJtNvCdMn9VWaas/9FI+jMhQTMimlRn5HzdaqIfoxoUWkTV\nZ3leST8P2Lakn0J1xeGIpHkeEY2pTm7v7Nnttq8Hri/zvwD2HiDPM8A7OnG8BM2IaNY4v4vRcBI0\nI6JRna5pNi1BMyKaMwHu3J6gGRENau/a8vEoQTMimpXmeURETR7/j7MYToJmRDQrNc2IiDZ0d8xM\n0IyIZqm3u9vnCZoR0RyTk9sjIuoSzsntERFtSdCMiGhDgmZERE3p04yIaE9GzyMianOa5xERtZkE\nzYiItnR36zxBMyKalfM0IyLakaAZEVGTDT3d3T7PI3wjoln28NMwJM2QdJ2keyTdLemvS/o2kuZK\nWlj+bl3SJelLkhZJWiBpz5EWP0EzIprVgaAJPA982PYewD7AByXtQfU883m2dwfm8eLzzQ8Hdi/T\nScA5Iy1+gmZENMdAr4efhtuNvcz2rWX+ceBeYDowC7iwZLsQOKrMzwK+4coNwBRJO4zkJSRoRkSD\nDO4dfmqDpJnA7wI3AtNsLyurHgKmlfnpwOKWzZaUtLZlICgimmPqDgRNlTS/ZXmO7Tn9M0naHPh/\nwMm2fy3pxUPZltTxofoEzYhoVr0+yxW29xoqg6QNqQLmJbb/rSQ/LGkH28tK83t5SV8KzGjZfKeS\n1rY0zyOiWZ0ZPRdwHnCv7X9sWXUVMLvMzwa+05J+fBlF3wdY3dKMb0tqmhHRoI7dsGNf4D3AnZJu\nL2mfAM4ErpB0IvAAcHRZdzVwBLAIeAo4YaQHTtCMiOYY6MCt4Wz/FNAgqw8aIL+BD67zgUnQjIim\n5TLKiIi6uv8yygTNiGiOwW2ehzneJGhGRLNqXPEzniVoRkSz0qcZEVGT3ZHR87GUoBkRzUpNMyKi\nLuOenrEuxDpJ0IyI5vTdGq6LJWhGRLNyylFERD0GnJpmRERNdmqaERHt6PaBILnLh/8BJD1CdRuo\niWgqsGKsCxG1TeTPaxfb263LDiT9kOo9Gs4K24ety7FGy4QImhOZpPnD3cE6xo98XhNf7tweEdGG\nBM2IiDYkaI5/L3kCX4xr+bwmuATNcW6gx5Y2RVKPpNsl3SXpW5I2XYd97S/pe2X+bZJOHSLvFEl/\nMYJjnCHpIyMtYyeM5ecVzUjQjKE8bft1tl8DPAe8v3VlebJf298h21fZPnOILFOAtoNmRBMSNKOu\nnwC7SZop6b8lfQO4C5gh6RBJP5d0a6mRbg4g6TBJ90m6Ffjjvh1Jeq+kr5T5aZK+LemOMr2J6omC\nLy+13C+UfH8r6WZJCyR9qmVfn5R0v6SfAq9s7N2I9VZObo9hSZoMHA78sCTtDsy2fYOkqcBpwJtt\nPynpY8Apkj4PnAscSPXY1MsH2f2XgP+0/UeSJgGbA6cCr7H9unL8Q8ox96Z6AuFVkv4AeBI4Bngd\n1Xf5VuCWzr76iLUlaMZQNml5pvRPgPOAHYEHbN9Q0vcB9gB+JgngZcDPgVcBv7S9EEDSxcBJAxzj\nQOB4ANs9wGpJW/fLc0iZbivLm1MF0S2Ab9t+qhzjqnV6tRE1JGjGUJ7uq+31KYHxydYkYK7tY/vl\nW2u7dSTg/9r+Wr9jnNzBY0TUkj7NWFc3APtK2g1A0maSXgHcB8yU9PKS79hBtp8HfKBsO0nSVsDj\nVLXIPtcAf9rSVzpd0vbAj4GjJG0iaQvgrR1+bREvkaAZ68T2I8B7gUslLaA0zW0/Q9Uc/34ZCFo+\nyC7+GjhA0p1U/ZF72F5J1dy/S9IXbF8LfBP4ecl3JbCF7Vup+krvAH4A3DxqLzSiyLXnERFtSE0z\nIqINCZoREW1I0IyIaEOCZkREGxI0IyLakKAZEdGGBM2IiDb8f4yx2q5TVyY1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aokdV0khofrA",
        "colab_type": "text"
      },
      "source": [
        "## Predicting a single new observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n6aYrO0ofrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting a single new observation\n",
        "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
        "Geography: France\n",
        "Credit Score: 600\n",
        "Gender: Male\n",
        "Age: 40\n",
        "Tenure: 3\n",
        "Balance: 60000\n",
        "Number of Products: 2\n",
        "Has Credit Card: Yes\n",
        "Is Active Member: Yes\n",
        "Estimated Salary: 50000\"\"\"\n",
        "single_value = array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])\n",
        "#single_value = array([['France', 0, 600, 'Male', 40, 3, 60000, 2, 1, 1, 50000]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACltJLj6ofrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c06b49ad-3c0f-4ffe-914d-58ec369f73e0"
      },
      "source": [
        "# ANN input is matrix, not vector\n",
        "single_value"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.e+00, 0.e+00, 6.e+02, 1.e+00, 4.e+01, 3.e+00, 6.e+04, 2.e+00,\n",
              "        1.e+00, 1.e+00, 5.e+04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7sfK6oSofre",
        "colab_type": "text"
      },
      "source": [
        "### you need to apply EXACTLY the same pipeline as during training !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duFMZ-SZofrg",
        "colab_type": "text"
      },
      "source": [
        "### get back transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgXtYMy1ofrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "4da48648-c6b0-4d6b-cb94-08bd0cc2d725"
      },
      "source": [
        "url = 'https://github.com/IALeMans/Meetup_ai-basics_2019-2/raw/master/transformers.p'\n",
        "filename = wget.download(url)\n",
        "\n",
        "transformers_name = ['labelencoder_X_1', 'labelencoder_X_2', 'onehotencoder', 'scaler']\n",
        "f = open(filename, 'rb')\n",
        "transformer = {}\n",
        "for transformer_name in transformers_name:\n",
        "    transformer[transformer_name]=(pickle.load(f))\n",
        "f.close()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.21.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator OneHotEncoder from version 0.21.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBxvFfz5ofsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "18f9ff7d-6e08-4e6e-9f6a-8c4adf1d8f26"
      },
      "source": [
        "transformer"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labelencoder_X_1': LabelEncoder(),\n",
              " 'labelencoder_X_2': LabelEncoder(),\n",
              " 'onehotencoder': OneHotEncoder(categorical_features=[1], categories=None, drop=None,\n",
              "               dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
              "               n_values=None, sparse=True),\n",
              " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8yKJrp7ofsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6aa9303-965f-41d4-e0c7-9aaece119034"
      },
      "source": [
        "new_prediction = classifier.predict(transformer['scaler'].transform(single_value))\n",
        "new_prediction_class = new_prediction > 0.5\n",
        "print(new_prediction, new_prediction_class)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.05921021]] [[False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL5syixVofsf",
        "colab_type": "text"
      },
      "source": [
        "# Part 4 - Evaluating, Improving and Tuning the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g10CVt65ofsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier():\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
        "accuracies = cross_val_score(estimator = classifier, X = dataset['X_train'], y = dataset['y_train'], cv = 10, n_jobs = -1)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFD9XvZHofsx",
        "colab_type": "code",
        "colab": {},
        "outputId": "d59eeeac-4a41-4793-ed94-5f38d4be12d4"
      },
      "source": [
        "classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.wrappers.scikit_learn.KerasClassifier at 0x7f27816cf6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qURFJs70ofs-",
        "colab_type": "code",
        "colab": {},
        "outputId": "35ad4b85-1e75-4d8c-f91e-93e98e27beb8"
      },
      "source": [
        "accuracies"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.83499998, 0.83625001, 0.83625001, 0.82999998, 0.84875   ,\n",
              "       0.83499998, 0.83875   , 0.85874999, 0.8075    , 0.79500002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9uKd8TeoftL",
        "colab_type": "code",
        "colab": {},
        "outputId": "59b494fa-b124-43f5-fb8f-113cf05e4862"
      },
      "source": [
        "mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8321249961853028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2j1mOpOoftY",
        "colab_type": "code",
        "colab": {},
        "outputId": "87d692b6-8b40-481e-c1c1-776533b42743"
      },
      "source": [
        "variance"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01751828719095433"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPenQVeqoftg",
        "colab_type": "text"
      },
      "source": [
        "## Improving the ANN : Dropout Regularization to reduce overfitting if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIrnEicwofti",
        "colab_type": "code",
        "colab": {},
        "outputId": "9b0fdfd1-dca7-47c8-83c8-4d57872b3288"
      },
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "classifier.add(Dropout(p = 0.1))\n",
        "\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(p = 0.1))\n",
        "\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX9dbnWWoftp",
        "colab_type": "code",
        "colab": {},
        "outputId": "e4d0ee74-60d6-49a4-d060-99d8c5af217d"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_72 (Dense)             (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4xAUIpjoftx",
        "colab_type": "code",
        "colab": {},
        "outputId": "d15fdc52-a992-4bca-ecbd-3fcd37bdc3b7"
      },
      "source": [
        "history = classifier.fit(dataset['X_train'], dataset['y_train'], validation_split=0.25, epochs=300, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6000 samples, validate on 2000 samples\n",
            "Epoch 1/300\n",
            "6000/6000 [==============================] - 1s 133us/step - loss: 0.6814 - accuracy: 0.7887 - val_loss: 0.6647 - val_accuracy: 0.7995\n",
            "Epoch 2/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.6317 - accuracy: 0.7948 - val_loss: 0.5833 - val_accuracy: 0.7995\n",
            "Epoch 3/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.5333 - accuracy: 0.7948 - val_loss: 0.4842 - val_accuracy: 0.7995\n",
            "Epoch 4/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4673 - accuracy: 0.7948 - val_loss: 0.4503 - val_accuracy: 0.7995\n",
            "Epoch 5/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4496 - accuracy: 0.7948 - val_loss: 0.4442 - val_accuracy: 0.7995\n",
            "Epoch 6/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4450 - accuracy: 0.7948 - val_loss: 0.4414 - val_accuracy: 0.7995\n",
            "Epoch 7/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4428 - accuracy: 0.7948 - val_loss: 0.4395 - val_accuracy: 0.7995\n",
            "Epoch 8/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4427 - accuracy: 0.7948 - val_loss: 0.4378 - val_accuracy: 0.7995\n",
            "Epoch 9/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4373 - accuracy: 0.7948 - val_loss: 0.4365 - val_accuracy: 0.7995\n",
            "Epoch 10/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4378 - accuracy: 0.7948 - val_loss: 0.4356 - val_accuracy: 0.7995\n",
            "Epoch 11/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4369 - accuracy: 0.7948 - val_loss: 0.4346 - val_accuracy: 0.7995\n",
            "Epoch 12/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4381 - accuracy: 0.7948 - val_loss: 0.4336 - val_accuracy: 0.7995\n",
            "Epoch 13/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4343 - accuracy: 0.7948 - val_loss: 0.4331 - val_accuracy: 0.7995\n",
            "Epoch 14/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4361 - accuracy: 0.7948 - val_loss: 0.4322 - val_accuracy: 0.7995\n",
            "Epoch 15/300\n",
            "6000/6000 [==============================] - 0s 35us/step - loss: 0.4343 - accuracy: 0.7948 - val_loss: 0.4314 - val_accuracy: 0.7995\n",
            "Epoch 16/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4359 - accuracy: 0.7948 - val_loss: 0.4307 - val_accuracy: 0.7995\n",
            "Epoch 17/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4327 - accuracy: 0.7948 - val_loss: 0.4298 - val_accuracy: 0.7995\n",
            "Epoch 18/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4337 - accuracy: 0.7948 - val_loss: 0.4291 - val_accuracy: 0.7995\n",
            "Epoch 19/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4319 - accuracy: 0.7948 - val_loss: 0.4282 - val_accuracy: 0.7995\n",
            "Epoch 20/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4326 - accuracy: 0.7948 - val_loss: 0.4277 - val_accuracy: 0.7995\n",
            "Epoch 21/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4302 - accuracy: 0.7948 - val_loss: 0.4272 - val_accuracy: 0.7995\n",
            "Epoch 22/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4313 - accuracy: 0.7948 - val_loss: 0.4266 - val_accuracy: 0.7995\n",
            "Epoch 23/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4278 - accuracy: 0.7948 - val_loss: 0.4264 - val_accuracy: 0.7995\n",
            "Epoch 24/300\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.4270 - accuracy: 0.7948 - val_loss: 0.4263 - val_accuracy: 0.7995\n",
            "Epoch 25/300\n",
            "6000/6000 [==============================] - 0s 43us/step - loss: 0.4302 - accuracy: 0.7948 - val_loss: 0.4260 - val_accuracy: 0.7995\n",
            "Epoch 26/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4255 - accuracy: 0.7948 - val_loss: 0.4257 - val_accuracy: 0.7995\n",
            "Epoch 27/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4299 - accuracy: 0.7948 - val_loss: 0.4255 - val_accuracy: 0.7995\n",
            "Epoch 28/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4279 - accuracy: 0.7948 - val_loss: 0.4254 - val_accuracy: 0.7995\n",
            "Epoch 29/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4282 - accuracy: 0.7948 - val_loss: 0.4251 - val_accuracy: 0.7995\n",
            "Epoch 30/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4289 - accuracy: 0.7948 - val_loss: 0.4247 - val_accuracy: 0.7995\n",
            "Epoch 31/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4286 - accuracy: 0.7948 - val_loss: 0.4244 - val_accuracy: 0.7995\n",
            "Epoch 32/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4298 - accuracy: 0.7948 - val_loss: 0.4242 - val_accuracy: 0.7995\n",
            "Epoch 33/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4295 - accuracy: 0.7948 - val_loss: 0.4240 - val_accuracy: 0.7995\n",
            "Epoch 34/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4235 - accuracy: 0.7948 - val_loss: 0.4241 - val_accuracy: 0.7995\n",
            "Epoch 35/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4242 - accuracy: 0.7948 - val_loss: 0.4241 - val_accuracy: 0.7995\n",
            "Epoch 36/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4269 - accuracy: 0.7948 - val_loss: 0.4238 - val_accuracy: 0.7995\n",
            "Epoch 37/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4241 - accuracy: 0.7948 - val_loss: 0.4239 - val_accuracy: 0.7995\n",
            "Epoch 38/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4296 - accuracy: 0.7948 - val_loss: 0.4235 - val_accuracy: 0.7995\n",
            "Epoch 39/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4246 - accuracy: 0.7948 - val_loss: 0.4237 - val_accuracy: 0.7995\n",
            "Epoch 40/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4294 - accuracy: 0.7948 - val_loss: 0.4234 - val_accuracy: 0.7995\n",
            "Epoch 41/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4268 - accuracy: 0.7948 - val_loss: 0.4231 - val_accuracy: 0.7995\n",
            "Epoch 42/300\n",
            "6000/6000 [==============================] - 0s 35us/step - loss: 0.4277 - accuracy: 0.7948 - val_loss: 0.4227 - val_accuracy: 0.7995\n",
            "Epoch 43/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4308 - accuracy: 0.7948 - val_loss: 0.4224 - val_accuracy: 0.7995\n",
            "Epoch 44/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4268 - accuracy: 0.7948 - val_loss: 0.4226 - val_accuracy: 0.7995\n",
            "Epoch 45/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4270 - accuracy: 0.8013 - val_loss: 0.4227 - val_accuracy: 0.7995\n",
            "Epoch 46/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.8000 - val_loss: 0.4224 - val_accuracy: 0.8250\n",
            "Epoch 47/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4304 - accuracy: 0.8185 - val_loss: 0.4222 - val_accuracy: 0.8255\n",
            "Epoch 48/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4268 - accuracy: 0.8252 - val_loss: 0.4220 - val_accuracy: 0.8250\n",
            "Epoch 49/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4259 - accuracy: 0.8190 - val_loss: 0.4223 - val_accuracy: 0.8255\n",
            "Epoch 50/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4260 - accuracy: 0.8232 - val_loss: 0.4220 - val_accuracy: 0.8260\n",
            "Epoch 51/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4278 - accuracy: 0.8238 - val_loss: 0.4218 - val_accuracy: 0.8250\n",
            "Epoch 52/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4253 - accuracy: 0.8208 - val_loss: 0.4218 - val_accuracy: 0.8270\n",
            "Epoch 53/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4278 - accuracy: 0.8240 - val_loss: 0.4217 - val_accuracy: 0.8260\n",
            "Epoch 54/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4270 - accuracy: 0.8223 - val_loss: 0.4217 - val_accuracy: 0.8250\n",
            "Epoch 55/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4260 - accuracy: 0.8252 - val_loss: 0.4214 - val_accuracy: 0.8255\n",
            "Epoch 56/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4242 - accuracy: 0.8213 - val_loss: 0.4211 - val_accuracy: 0.8265\n",
            "Epoch 57/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4254 - accuracy: 0.8222 - val_loss: 0.4213 - val_accuracy: 0.8265\n",
            "Epoch 58/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4269 - accuracy: 0.8248 - val_loss: 0.4210 - val_accuracy: 0.8280\n",
            "Epoch 59/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4231 - accuracy: 0.8218 - val_loss: 0.4213 - val_accuracy: 0.8275\n",
            "Epoch 60/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4211 - accuracy: 0.8265 - val_loss: 0.4210 - val_accuracy: 0.8285\n",
            "Epoch 61/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4248 - accuracy: 0.8238 - val_loss: 0.4210 - val_accuracy: 0.8285\n",
            "Epoch 62/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4248 - accuracy: 0.8203 - val_loss: 0.4212 - val_accuracy: 0.8285\n",
            "Epoch 63/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4225 - accuracy: 0.8265 - val_loss: 0.4211 - val_accuracy: 0.8275\n",
            "Epoch 64/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4214 - accuracy: 0.8288 - val_loss: 0.4208 - val_accuracy: 0.8285\n",
            "Epoch 65/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4284 - accuracy: 0.8290 - val_loss: 0.4208 - val_accuracy: 0.8285\n",
            "Epoch 66/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4246 - accuracy: 0.8275 - val_loss: 0.4204 - val_accuracy: 0.8290\n",
            "Epoch 67/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4252 - accuracy: 0.8235 - val_loss: 0.4203 - val_accuracy: 0.8285\n",
            "Epoch 68/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4215 - accuracy: 0.8272 - val_loss: 0.4207 - val_accuracy: 0.8285\n",
            "Epoch 69/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4239 - accuracy: 0.8265 - val_loss: 0.4202 - val_accuracy: 0.8285\n",
            "Epoch 70/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4241 - accuracy: 0.8278 - val_loss: 0.4201 - val_accuracy: 0.8280\n",
            "Epoch 71/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4279 - accuracy: 0.8272 - val_loss: 0.4199 - val_accuracy: 0.8285\n",
            "Epoch 72/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4248 - accuracy: 0.8272 - val_loss: 0.4203 - val_accuracy: 0.8290\n",
            "Epoch 73/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4256 - accuracy: 0.8262 - val_loss: 0.4200 - val_accuracy: 0.8285\n",
            "Epoch 74/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4222 - accuracy: 0.8268 - val_loss: 0.4200 - val_accuracy: 0.8280\n",
            "Epoch 75/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4276 - accuracy: 0.8273 - val_loss: 0.4197 - val_accuracy: 0.8290\n",
            "Epoch 76/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4227 - accuracy: 0.8280 - val_loss: 0.4196 - val_accuracy: 0.8290\n",
            "Epoch 77/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4237 - accuracy: 0.8272 - val_loss: 0.4194 - val_accuracy: 0.8270\n",
            "Epoch 78/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4253 - accuracy: 0.8257 - val_loss: 0.4196 - val_accuracy: 0.8270\n",
            "Epoch 79/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4220 - accuracy: 0.8288 - val_loss: 0.4193 - val_accuracy: 0.8275\n",
            "Epoch 80/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4264 - accuracy: 0.8297 - val_loss: 0.4193 - val_accuracy: 0.8285\n",
            "Epoch 81/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4222 - accuracy: 0.8278 - val_loss: 0.4196 - val_accuracy: 0.8285\n",
            "Epoch 82/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4270 - accuracy: 0.8260 - val_loss: 0.4196 - val_accuracy: 0.8280\n",
            "Epoch 83/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4261 - accuracy: 0.8312 - val_loss: 0.4197 - val_accuracy: 0.8280\n",
            "Epoch 84/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4289 - accuracy: 0.8267 - val_loss: 0.4195 - val_accuracy: 0.8285\n",
            "Epoch 85/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4221 - accuracy: 0.8305 - val_loss: 0.4195 - val_accuracy: 0.8290\n",
            "Epoch 86/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4238 - accuracy: 0.8278 - val_loss: 0.4191 - val_accuracy: 0.8290\n",
            "Epoch 87/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4247 - accuracy: 0.8277 - val_loss: 0.4193 - val_accuracy: 0.8290\n",
            "Epoch 88/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4229 - accuracy: 0.8303 - val_loss: 0.4192 - val_accuracy: 0.8280\n",
            "Epoch 89/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4222 - accuracy: 0.8315 - val_loss: 0.4191 - val_accuracy: 0.8295\n",
            "Epoch 90/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4226 - accuracy: 0.8285 - val_loss: 0.4189 - val_accuracy: 0.8285\n",
            "Epoch 91/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.8283 - val_loss: 0.4191 - val_accuracy: 0.8285\n",
            "Epoch 92/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4243 - accuracy: 0.8275 - val_loss: 0.4189 - val_accuracy: 0.8285\n",
            "Epoch 93/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4253 - accuracy: 0.8300 - val_loss: 0.4191 - val_accuracy: 0.8285\n",
            "Epoch 94/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4198 - accuracy: 0.8293 - val_loss: 0.4190 - val_accuracy: 0.8285\n",
            "Epoch 95/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4211 - accuracy: 0.8283 - val_loss: 0.4188 - val_accuracy: 0.8290\n",
            "Epoch 96/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4229 - accuracy: 0.8285 - val_loss: 0.4189 - val_accuracy: 0.8280\n",
            "Epoch 97/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4245 - accuracy: 0.8317 - val_loss: 0.4191 - val_accuracy: 0.8280\n",
            "Epoch 98/300\n",
            "6000/6000 [==============================] - 0s 43us/step - loss: 0.4263 - accuracy: 0.8303 - val_loss: 0.4190 - val_accuracy: 0.8290\n",
            "Epoch 99/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4201 - accuracy: 0.8295 - val_loss: 0.4189 - val_accuracy: 0.8290\n",
            "Epoch 100/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4235 - accuracy: 0.8285 - val_loss: 0.4189 - val_accuracy: 0.8290\n",
            "Epoch 101/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4252 - accuracy: 0.8282 - val_loss: 0.4186 - val_accuracy: 0.8285\n",
            "Epoch 102/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4237 - accuracy: 0.8300 - val_loss: 0.4185 - val_accuracy: 0.8295\n",
            "Epoch 103/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4182 - accuracy: 0.8285 - val_loss: 0.4185 - val_accuracy: 0.8295\n",
            "Epoch 104/300\n",
            "6000/6000 [==============================] - 0s 43us/step - loss: 0.4239 - accuracy: 0.8288 - val_loss: 0.4188 - val_accuracy: 0.8290\n",
            "Epoch 105/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4222 - accuracy: 0.8307 - val_loss: 0.4184 - val_accuracy: 0.8285\n",
            "Epoch 106/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4224 - accuracy: 0.8292 - val_loss: 0.4186 - val_accuracy: 0.8285\n",
            "Epoch 107/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4256 - accuracy: 0.8303 - val_loss: 0.4185 - val_accuracy: 0.8280\n",
            "Epoch 108/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4241 - accuracy: 0.8278 - val_loss: 0.4184 - val_accuracy: 0.8285\n",
            "Epoch 109/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4270 - accuracy: 0.8300 - val_loss: 0.4187 - val_accuracy: 0.8285\n",
            "Epoch 110/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4231 - accuracy: 0.8280 - val_loss: 0.4185 - val_accuracy: 0.8290\n",
            "Epoch 111/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4241 - accuracy: 0.8278 - val_loss: 0.4185 - val_accuracy: 0.8280\n",
            "Epoch 112/300\n",
            "6000/6000 [==============================] - 0s 45us/step - loss: 0.4239 - accuracy: 0.8297 - val_loss: 0.4186 - val_accuracy: 0.8275\n",
            "Epoch 113/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4220 - accuracy: 0.8323 - val_loss: 0.4185 - val_accuracy: 0.8280\n",
            "Epoch 114/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4249 - accuracy: 0.8283 - val_loss: 0.4185 - val_accuracy: 0.8280\n",
            "Epoch 115/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4214 - accuracy: 0.8278 - val_loss: 0.4185 - val_accuracy: 0.8265\n",
            "Epoch 116/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4228 - accuracy: 0.8270 - val_loss: 0.4184 - val_accuracy: 0.8285\n",
            "Epoch 117/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4206 - accuracy: 0.8288 - val_loss: 0.4179 - val_accuracy: 0.8300\n",
            "Epoch 118/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4254 - accuracy: 0.8302 - val_loss: 0.4179 - val_accuracy: 0.8295\n",
            "Epoch 119/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4244 - accuracy: 0.8290 - val_loss: 0.4177 - val_accuracy: 0.8285\n",
            "Epoch 120/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4210 - accuracy: 0.8287 - val_loss: 0.4181 - val_accuracy: 0.8280\n",
            "Epoch 121/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4211 - accuracy: 0.8278 - val_loss: 0.4182 - val_accuracy: 0.8275\n",
            "Epoch 122/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4221 - accuracy: 0.8327 - val_loss: 0.4182 - val_accuracy: 0.8290\n",
            "Epoch 123/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4285 - accuracy: 0.8282 - val_loss: 0.4183 - val_accuracy: 0.8285\n",
            "Epoch 124/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4273 - accuracy: 0.8295 - val_loss: 0.4183 - val_accuracy: 0.8285\n",
            "Epoch 125/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4260 - accuracy: 0.8307 - val_loss: 0.4184 - val_accuracy: 0.8285\n",
            "Epoch 126/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4227 - accuracy: 0.8293 - val_loss: 0.4183 - val_accuracy: 0.8280\n",
            "Epoch 127/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4297 - accuracy: 0.8280 - val_loss: 0.4179 - val_accuracy: 0.8280\n",
            "Epoch 128/300\n",
            "6000/6000 [==============================] - 0s 43us/step - loss: 0.4261 - accuracy: 0.8297 - val_loss: 0.4180 - val_accuracy: 0.8285\n",
            "Epoch 129/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4193 - accuracy: 0.8285 - val_loss: 0.4183 - val_accuracy: 0.8290\n",
            "Epoch 130/300\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.4251 - accuracy: 0.8283 - val_loss: 0.4183 - val_accuracy: 0.8285\n",
            "Epoch 131/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4219 - accuracy: 0.8320 - val_loss: 0.4180 - val_accuracy: 0.8285\n",
            "Epoch 132/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4249 - accuracy: 0.8258 - val_loss: 0.4183 - val_accuracy: 0.8265\n",
            "Epoch 133/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4195 - accuracy: 0.8293 - val_loss: 0.4183 - val_accuracy: 0.8290\n",
            "Epoch 134/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4221 - accuracy: 0.8293 - val_loss: 0.4179 - val_accuracy: 0.8295\n",
            "Epoch 135/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4253 - accuracy: 0.8307 - val_loss: 0.4178 - val_accuracy: 0.8295\n",
            "Epoch 136/300\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.4240 - accuracy: 0.8282 - val_loss: 0.4181 - val_accuracy: 0.8285\n",
            "Epoch 137/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4259 - accuracy: 0.8268 - val_loss: 0.4179 - val_accuracy: 0.8280\n",
            "Epoch 138/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4234 - accuracy: 0.8315 - val_loss: 0.4176 - val_accuracy: 0.8285\n",
            "Epoch 139/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4220 - accuracy: 0.8298 - val_loss: 0.4177 - val_accuracy: 0.8280\n",
            "Epoch 140/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4204 - accuracy: 0.8275 - val_loss: 0.4177 - val_accuracy: 0.8270\n",
            "Epoch 141/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4252 - accuracy: 0.8272 - val_loss: 0.4175 - val_accuracy: 0.8275\n",
            "Epoch 142/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4257 - accuracy: 0.8267 - val_loss: 0.4174 - val_accuracy: 0.8295\n",
            "Epoch 143/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4251 - accuracy: 0.8280 - val_loss: 0.4175 - val_accuracy: 0.8275\n",
            "Epoch 144/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4248 - accuracy: 0.8290 - val_loss: 0.4174 - val_accuracy: 0.8280\n",
            "Epoch 145/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4240 - accuracy: 0.8288 - val_loss: 0.4174 - val_accuracy: 0.8270\n",
            "Epoch 146/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4251 - accuracy: 0.8275 - val_loss: 0.4175 - val_accuracy: 0.8270\n",
            "Epoch 147/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4210 - accuracy: 0.8283 - val_loss: 0.4176 - val_accuracy: 0.8285\n",
            "Epoch 148/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4225 - accuracy: 0.8280 - val_loss: 0.4177 - val_accuracy: 0.8280\n",
            "Epoch 149/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4213 - accuracy: 0.8318 - val_loss: 0.4176 - val_accuracy: 0.8270\n",
            "Epoch 150/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4262 - accuracy: 0.8287 - val_loss: 0.4174 - val_accuracy: 0.8275\n",
            "Epoch 151/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4232 - accuracy: 0.8270 - val_loss: 0.4175 - val_accuracy: 0.8265\n",
            "Epoch 152/300\n",
            "6000/6000 [==============================] - 0s 43us/step - loss: 0.4223 - accuracy: 0.8283 - val_loss: 0.4177 - val_accuracy: 0.8265\n",
            "Epoch 153/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4223 - accuracy: 0.8283 - val_loss: 0.4172 - val_accuracy: 0.8270\n",
            "Epoch 154/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4245 - accuracy: 0.8287 - val_loss: 0.4171 - val_accuracy: 0.8270\n",
            "Epoch 155/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4228 - accuracy: 0.8258 - val_loss: 0.4171 - val_accuracy: 0.8270\n",
            "Epoch 156/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4245 - accuracy: 0.8298 - val_loss: 0.4169 - val_accuracy: 0.8290\n",
            "Epoch 157/300\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4225 - accuracy: 0.8308 - val_loss: 0.4168 - val_accuracy: 0.8295\n",
            "Epoch 158/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4243 - accuracy: 0.8265 - val_loss: 0.4168 - val_accuracy: 0.8275\n",
            "Epoch 159/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4257 - accuracy: 0.8322 - val_loss: 0.4168 - val_accuracy: 0.8280\n",
            "Epoch 160/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4237 - accuracy: 0.8305 - val_loss: 0.4167 - val_accuracy: 0.8265\n",
            "Epoch 161/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4219 - accuracy: 0.8342 - val_loss: 0.4168 - val_accuracy: 0.8275\n",
            "Epoch 162/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4236 - accuracy: 0.8272 - val_loss: 0.4167 - val_accuracy: 0.8270\n",
            "Epoch 163/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4249 - accuracy: 0.8293 - val_loss: 0.4166 - val_accuracy: 0.8275\n",
            "Epoch 164/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4225 - accuracy: 0.8317 - val_loss: 0.4167 - val_accuracy: 0.8265\n",
            "Epoch 165/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4233 - accuracy: 0.8270 - val_loss: 0.4168 - val_accuracy: 0.8270\n",
            "Epoch 166/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4195 - accuracy: 0.8312 - val_loss: 0.4169 - val_accuracy: 0.8280\n",
            "Epoch 167/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4217 - accuracy: 0.8323 - val_loss: 0.4166 - val_accuracy: 0.8280\n",
            "Epoch 168/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4209 - accuracy: 0.8292 - val_loss: 0.4167 - val_accuracy: 0.8285\n",
            "Epoch 169/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4269 - accuracy: 0.8285 - val_loss: 0.4163 - val_accuracy: 0.8280\n",
            "Epoch 170/300\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4230 - accuracy: 0.8303 - val_loss: 0.4165 - val_accuracy: 0.8280\n",
            "Epoch 171/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4208 - accuracy: 0.8278 - val_loss: 0.4165 - val_accuracy: 0.8285\n",
            "Epoch 172/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4237 - accuracy: 0.8308 - val_loss: 0.4162 - val_accuracy: 0.8285\n",
            "Epoch 173/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4245 - accuracy: 0.8293 - val_loss: 0.4163 - val_accuracy: 0.8290\n",
            "Epoch 174/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4210 - accuracy: 0.8295 - val_loss: 0.4163 - val_accuracy: 0.8270\n",
            "Epoch 175/300\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4200 - accuracy: 0.8292 - val_loss: 0.4161 - val_accuracy: 0.8300\n",
            "Epoch 176/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4231 - accuracy: 0.8285 - val_loss: 0.4164 - val_accuracy: 0.8300\n",
            "Epoch 177/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4254 - accuracy: 0.8287 - val_loss: 0.4165 - val_accuracy: 0.8280\n",
            "Epoch 178/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4234 - accuracy: 0.8313 - val_loss: 0.4162 - val_accuracy: 0.8300\n",
            "Epoch 179/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4245 - accuracy: 0.8287 - val_loss: 0.4161 - val_accuracy: 0.8285\n",
            "Epoch 180/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4200 - accuracy: 0.8300 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 181/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4215 - accuracy: 0.8298 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 182/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4232 - accuracy: 0.8285 - val_loss: 0.4162 - val_accuracy: 0.8285\n",
            "Epoch 183/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4220 - accuracy: 0.8308 - val_loss: 0.4162 - val_accuracy: 0.8285\n",
            "Epoch 184/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4208 - accuracy: 0.8290 - val_loss: 0.4160 - val_accuracy: 0.8275\n",
            "Epoch 185/300\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4228 - accuracy: 0.8273 - val_loss: 0.4160 - val_accuracy: 0.8285\n",
            "Epoch 186/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4219 - accuracy: 0.8323 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 187/300\n",
            "6000/6000 [==============================] - 0s 48us/step - loss: 0.4213 - accuracy: 0.8307 - val_loss: 0.4161 - val_accuracy: 0.8285\n",
            "Epoch 188/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4187 - accuracy: 0.8308 - val_loss: 0.4160 - val_accuracy: 0.8280\n",
            "Epoch 189/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4233 - accuracy: 0.8282 - val_loss: 0.4162 - val_accuracy: 0.8295\n",
            "Epoch 190/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4203 - accuracy: 0.8308 - val_loss: 0.4163 - val_accuracy: 0.8290\n",
            "Epoch 191/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4210 - accuracy: 0.8317 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 192/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4212 - accuracy: 0.8305 - val_loss: 0.4161 - val_accuracy: 0.8295\n",
            "Epoch 193/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4172 - accuracy: 0.8307 - val_loss: 0.4161 - val_accuracy: 0.8285\n",
            "Epoch 194/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4224 - accuracy: 0.8277 - val_loss: 0.4162 - val_accuracy: 0.8280\n",
            "Epoch 195/300\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4183 - accuracy: 0.8280 - val_loss: 0.4160 - val_accuracy: 0.8265\n",
            "Epoch 196/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4248 - accuracy: 0.8275 - val_loss: 0.4161 - val_accuracy: 0.8285\n",
            "Epoch 197/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.8332 - val_loss: 0.4160 - val_accuracy: 0.8290\n",
            "Epoch 198/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4212 - accuracy: 0.8282 - val_loss: 0.4160 - val_accuracy: 0.8290\n",
            "Epoch 199/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4243 - accuracy: 0.8315 - val_loss: 0.4164 - val_accuracy: 0.8290\n",
            "Epoch 200/300\n",
            "6000/6000 [==============================] - 0s 36us/step - loss: 0.4236 - accuracy: 0.8303 - val_loss: 0.4163 - val_accuracy: 0.8290\n",
            "Epoch 201/300\n",
            "6000/6000 [==============================] - 0s 43us/step - loss: 0.4233 - accuracy: 0.8293 - val_loss: 0.4164 - val_accuracy: 0.8290\n",
            "Epoch 202/300\n",
            "6000/6000 [==============================] - 0s 51us/step - loss: 0.4198 - accuracy: 0.8285 - val_loss: 0.4163 - val_accuracy: 0.8290\n",
            "Epoch 203/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4206 - accuracy: 0.8297 - val_loss: 0.4160 - val_accuracy: 0.8290\n",
            "Epoch 204/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4224 - accuracy: 0.8292 - val_loss: 0.4162 - val_accuracy: 0.8295\n",
            "Epoch 205/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4212 - accuracy: 0.8300 - val_loss: 0.4160 - val_accuracy: 0.8295\n",
            "Epoch 206/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4217 - accuracy: 0.8290 - val_loss: 0.4159 - val_accuracy: 0.8320\n",
            "Epoch 207/300\n",
            "6000/6000 [==============================] - 0s 44us/step - loss: 0.4238 - accuracy: 0.8297 - val_loss: 0.4160 - val_accuracy: 0.8285\n",
            "Epoch 208/300\n",
            "6000/6000 [==============================] - 0s 59us/step - loss: 0.4284 - accuracy: 0.8292 - val_loss: 0.4163 - val_accuracy: 0.8290\n",
            "Epoch 209/300\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.4218 - accuracy: 0.8310 - val_loss: 0.4162 - val_accuracy: 0.8285\n",
            "Epoch 210/300\n",
            "6000/6000 [==============================] - 0s 54us/step - loss: 0.4231 - accuracy: 0.8313 - val_loss: 0.4165 - val_accuracy: 0.8275\n",
            "Epoch 211/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4229 - accuracy: 0.8277 - val_loss: 0.4164 - val_accuracy: 0.8285\n",
            "Epoch 212/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4231 - accuracy: 0.8297 - val_loss: 0.4166 - val_accuracy: 0.8285\n",
            "Epoch 213/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4230 - accuracy: 0.8288 - val_loss: 0.4159 - val_accuracy: 0.8290\n",
            "Epoch 214/300\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.4231 - accuracy: 0.8313 - val_loss: 0.4160 - val_accuracy: 0.8285\n",
            "Epoch 215/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4200 - accuracy: 0.8288 - val_loss: 0.4164 - val_accuracy: 0.8290\n",
            "Epoch 216/300\n",
            "6000/6000 [==============================] - 0s 58us/step - loss: 0.4224 - accuracy: 0.8310 - val_loss: 0.4166 - val_accuracy: 0.8275\n",
            "Epoch 217/300\n",
            "6000/6000 [==============================] - 0s 45us/step - loss: 0.4201 - accuracy: 0.8282 - val_loss: 0.4165 - val_accuracy: 0.8280\n",
            "Epoch 218/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4187 - accuracy: 0.8305 - val_loss: 0.4167 - val_accuracy: 0.8270\n",
            "Epoch 219/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4223 - accuracy: 0.8310 - val_loss: 0.4165 - val_accuracy: 0.8275\n",
            "Epoch 220/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4236 - accuracy: 0.8265 - val_loss: 0.4162 - val_accuracy: 0.8280\n",
            "Epoch 221/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4191 - accuracy: 0.8313 - val_loss: 0.4165 - val_accuracy: 0.8275\n",
            "Epoch 222/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4175 - accuracy: 0.8303 - val_loss: 0.4164 - val_accuracy: 0.8280\n",
            "Epoch 223/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4223 - accuracy: 0.8315 - val_loss: 0.4164 - val_accuracy: 0.8270\n",
            "Epoch 224/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4252 - accuracy: 0.8342 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 225/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4209 - accuracy: 0.8302 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 226/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4185 - accuracy: 0.8295 - val_loss: 0.4165 - val_accuracy: 0.8280\n",
            "Epoch 227/300\n",
            "6000/6000 [==============================] - 0s 50us/step - loss: 0.4203 - accuracy: 0.8320 - val_loss: 0.4163 - val_accuracy: 0.8290\n",
            "Epoch 228/300\n",
            "6000/6000 [==============================] - 0s 53us/step - loss: 0.4209 - accuracy: 0.8267 - val_loss: 0.4162 - val_accuracy: 0.8275\n",
            "Epoch 229/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4194 - accuracy: 0.8307 - val_loss: 0.4162 - val_accuracy: 0.8280\n",
            "Epoch 230/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4220 - accuracy: 0.8288 - val_loss: 0.4161 - val_accuracy: 0.8295\n",
            "Epoch 231/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4199 - accuracy: 0.8332 - val_loss: 0.4166 - val_accuracy: 0.8290\n",
            "Epoch 232/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4240 - accuracy: 0.8287 - val_loss: 0.4163 - val_accuracy: 0.8265\n",
            "Epoch 233/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4225 - accuracy: 0.8268 - val_loss: 0.4166 - val_accuracy: 0.8265\n",
            "Epoch 234/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4236 - accuracy: 0.8298 - val_loss: 0.4164 - val_accuracy: 0.8275\n",
            "Epoch 235/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.8322 - val_loss: 0.4161 - val_accuracy: 0.8280\n",
            "Epoch 236/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4235 - accuracy: 0.8283 - val_loss: 0.4164 - val_accuracy: 0.8295\n",
            "Epoch 237/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4219 - accuracy: 0.8293 - val_loss: 0.4161 - val_accuracy: 0.8275\n",
            "Epoch 238/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4243 - accuracy: 0.8317 - val_loss: 0.4162 - val_accuracy: 0.8270\n",
            "Epoch 239/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4231 - accuracy: 0.8303 - val_loss: 0.4160 - val_accuracy: 0.8275\n",
            "Epoch 240/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4203 - accuracy: 0.8318 - val_loss: 0.4160 - val_accuracy: 0.8285\n",
            "Epoch 241/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4229 - accuracy: 0.8303 - val_loss: 0.4165 - val_accuracy: 0.8285\n",
            "Epoch 242/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4222 - accuracy: 0.8328 - val_loss: 0.4159 - val_accuracy: 0.8290\n",
            "Epoch 243/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4261 - accuracy: 0.8277 - val_loss: 0.4160 - val_accuracy: 0.8275\n",
            "Epoch 244/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4215 - accuracy: 0.8323 - val_loss: 0.4161 - val_accuracy: 0.8285\n",
            "Epoch 245/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4219 - accuracy: 0.8303 - val_loss: 0.4157 - val_accuracy: 0.8305\n",
            "Epoch 246/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4197 - accuracy: 0.8307 - val_loss: 0.4158 - val_accuracy: 0.8295\n",
            "Epoch 247/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4240 - accuracy: 0.8302 - val_loss: 0.4162 - val_accuracy: 0.8280\n",
            "Epoch 248/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4182 - accuracy: 0.8310 - val_loss: 0.4161 - val_accuracy: 0.8265\n",
            "Epoch 249/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4225 - accuracy: 0.8320 - val_loss: 0.4159 - val_accuracy: 0.8265\n",
            "Epoch 250/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4230 - accuracy: 0.8318 - val_loss: 0.4158 - val_accuracy: 0.8285\n",
            "Epoch 251/300\n",
            "6000/6000 [==============================] - 0s 45us/step - loss: 0.4227 - accuracy: 0.8313 - val_loss: 0.4159 - val_accuracy: 0.8280\n",
            "Epoch 252/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4246 - accuracy: 0.8308 - val_loss: 0.4158 - val_accuracy: 0.8300\n",
            "Epoch 253/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4219 - accuracy: 0.8277 - val_loss: 0.4157 - val_accuracy: 0.8290\n",
            "Epoch 254/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4184 - accuracy: 0.8307 - val_loss: 0.4159 - val_accuracy: 0.8290\n",
            "Epoch 255/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4191 - accuracy: 0.8340 - val_loss: 0.4154 - val_accuracy: 0.8290\n",
            "Epoch 256/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4254 - accuracy: 0.8295 - val_loss: 0.4152 - val_accuracy: 0.8280\n",
            "Epoch 257/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4230 - accuracy: 0.8298 - val_loss: 0.4154 - val_accuracy: 0.8295\n",
            "Epoch 258/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4254 - accuracy: 0.8300 - val_loss: 0.4153 - val_accuracy: 0.8300\n",
            "Epoch 259/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4237 - accuracy: 0.8288 - val_loss: 0.4153 - val_accuracy: 0.8290\n",
            "Epoch 260/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4219 - accuracy: 0.8288 - val_loss: 0.4154 - val_accuracy: 0.8315\n",
            "Epoch 261/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4212 - accuracy: 0.8298 - val_loss: 0.4155 - val_accuracy: 0.8305\n",
            "Epoch 262/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4208 - accuracy: 0.8315 - val_loss: 0.4156 - val_accuracy: 0.8280\n",
            "Epoch 263/300\n",
            "6000/6000 [==============================] - 0s 45us/step - loss: 0.4210 - accuracy: 0.8322 - val_loss: 0.4154 - val_accuracy: 0.8270\n",
            "Epoch 264/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4222 - accuracy: 0.8320 - val_loss: 0.4155 - val_accuracy: 0.8310\n",
            "Epoch 265/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.8298 - val_loss: 0.4153 - val_accuracy: 0.8270\n",
            "Epoch 266/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4211 - accuracy: 0.8308 - val_loss: 0.4156 - val_accuracy: 0.8270\n",
            "Epoch 267/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4226 - accuracy: 0.8315 - val_loss: 0.4156 - val_accuracy: 0.8260\n",
            "Epoch 268/300\n",
            "6000/6000 [==============================] - 0s 52us/step - loss: 0.4220 - accuracy: 0.8278 - val_loss: 0.4155 - val_accuracy: 0.8280\n",
            "Epoch 269/300\n",
            "6000/6000 [==============================] - 0s 46us/step - loss: 0.4227 - accuracy: 0.8323 - val_loss: 0.4159 - val_accuracy: 0.8250\n",
            "Epoch 270/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4214 - accuracy: 0.8327 - val_loss: 0.4158 - val_accuracy: 0.8275\n",
            "Epoch 271/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4207 - accuracy: 0.8333 - val_loss: 0.4159 - val_accuracy: 0.8265\n",
            "Epoch 272/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4202 - accuracy: 0.8318 - val_loss: 0.4160 - val_accuracy: 0.8290\n",
            "Epoch 273/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4218 - accuracy: 0.8312 - val_loss: 0.4155 - val_accuracy: 0.8285\n",
            "Epoch 274/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4232 - accuracy: 0.8293 - val_loss: 0.4157 - val_accuracy: 0.8290\n",
            "Epoch 275/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4208 - accuracy: 0.8295 - val_loss: 0.4156 - val_accuracy: 0.8285\n",
            "Epoch 276/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4231 - accuracy: 0.8292 - val_loss: 0.4156 - val_accuracy: 0.8295\n",
            "Epoch 277/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4218 - accuracy: 0.8303 - val_loss: 0.4159 - val_accuracy: 0.8280\n",
            "Epoch 278/300\n",
            "6000/6000 [==============================] - 0s 42us/step - loss: 0.4194 - accuracy: 0.8307 - val_loss: 0.4160 - val_accuracy: 0.8275\n",
            "Epoch 279/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4220 - accuracy: 0.8292 - val_loss: 0.4158 - val_accuracy: 0.8295\n",
            "Epoch 280/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4239 - accuracy: 0.8312 - val_loss: 0.4157 - val_accuracy: 0.8300\n",
            "Epoch 281/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4246 - accuracy: 0.8305 - val_loss: 0.4158 - val_accuracy: 0.8290\n",
            "Epoch 282/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4244 - accuracy: 0.8305 - val_loss: 0.4157 - val_accuracy: 0.8280\n",
            "Epoch 283/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4179 - accuracy: 0.8322 - val_loss: 0.4158 - val_accuracy: 0.8285\n",
            "Epoch 284/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4236 - accuracy: 0.8303 - val_loss: 0.4159 - val_accuracy: 0.8285\n",
            "Epoch 285/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4247 - accuracy: 0.8293 - val_loss: 0.4157 - val_accuracy: 0.8295\n",
            "Epoch 286/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4238 - accuracy: 0.8305 - val_loss: 0.4160 - val_accuracy: 0.8280\n",
            "Epoch 287/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.8305 - val_loss: 0.4162 - val_accuracy: 0.8300\n",
            "Epoch 288/300\n",
            "6000/6000 [==============================] - 0s 37us/step - loss: 0.4197 - accuracy: 0.8312 - val_loss: 0.4161 - val_accuracy: 0.8295\n",
            "Epoch 289/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4237 - accuracy: 0.8295 - val_loss: 0.4159 - val_accuracy: 0.8290\n",
            "Epoch 290/300\n",
            "6000/6000 [==============================] - 0s 47us/step - loss: 0.4217 - accuracy: 0.8270 - val_loss: 0.4160 - val_accuracy: 0.8295\n",
            "Epoch 291/300\n",
            "6000/6000 [==============================] - 0s 49us/step - loss: 0.4168 - accuracy: 0.8320 - val_loss: 0.4163 - val_accuracy: 0.8295\n",
            "Epoch 292/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4247 - accuracy: 0.8292 - val_loss: 0.4162 - val_accuracy: 0.8290\n",
            "Epoch 293/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4220 - accuracy: 0.8310 - val_loss: 0.4162 - val_accuracy: 0.8280\n",
            "Epoch 294/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4239 - accuracy: 0.8308 - val_loss: 0.4160 - val_accuracy: 0.8270\n",
            "Epoch 295/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4245 - accuracy: 0.8323 - val_loss: 0.4162 - val_accuracy: 0.8260\n",
            "Epoch 296/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4214 - accuracy: 0.8307 - val_loss: 0.4161 - val_accuracy: 0.8275\n",
            "Epoch 297/300\n",
            "6000/6000 [==============================] - 0s 40us/step - loss: 0.4269 - accuracy: 0.8312 - val_loss: 0.4159 - val_accuracy: 0.8280\n",
            "Epoch 298/300\n",
            "6000/6000 [==============================] - 0s 41us/step - loss: 0.4239 - accuracy: 0.8292 - val_loss: 0.4160 - val_accuracy: 0.8295\n",
            "Epoch 299/300\n",
            "6000/6000 [==============================] - 0s 39us/step - loss: 0.4218 - accuracy: 0.8278 - val_loss: 0.4160 - val_accuracy: 0.8280\n",
            "Epoch 300/300\n",
            "6000/6000 [==============================] - 0s 38us/step - loss: 0.4248 - accuracy: 0.8303 - val_loss: 0.4158 - val_accuracy: 0.8290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo91GqoEoft5",
        "colab_type": "code",
        "colab": {},
        "outputId": "2f836941-1cb6-4aaa-d3b6-f1d9a8bb9c4c"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KXXGkDsofuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# under fitting vs over fitting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2ESaL9BofuO",
        "colab_type": "text"
      },
      "source": [
        "# Tuning the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSbrar4PofuP",
        "colab_type": "code",
        "colab": {},
        "outputId": "8c455a98-4275-4b17-f16b-d43a02293d05"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def build_classifier(optimizer):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "    #classifier.add(Dropout(p = 0.1))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    #classifier.add(Dropout(p = 0.1))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "parameters = {'batch_size': [25, 32],\n",
        "              'epochs': [100, 500],\n",
        "              'optimizer': ['adam', 'rmsprop']}\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "grid_search = grid_search.fit(dataset['X_train'], dataset['y_train'])\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 156us/step - loss: 0.5734 - accuracy: 0.7953\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4365 - accuracy: 0.7971\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4302 - accuracy: 0.7971\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4276 - accuracy: 0.7971\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4250 - accuracy: 0.7971\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4227 - accuracy: 0.7971\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4204 - accuracy: 0.7971\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4187 - accuracy: 0.8083\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4175 - accuracy: 0.8197\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4164 - accuracy: 0.8232\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4155 - accuracy: 0.8253\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4144 - accuracy: 0.8271\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4135 - accuracy: 0.8293\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4128 - accuracy: 0.8290\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4123 - accuracy: 0.8299\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4113 - accuracy: 0.8299\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4111 - accuracy: 0.8313\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4108 - accuracy: 0.8313\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4098 - accuracy: 0.8332\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4100 - accuracy: 0.8329\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4090 - accuracy: 0.8335\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4088 - accuracy: 0.8349\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4087 - accuracy: 0.8347\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4083 - accuracy: 0.8347\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4079 - accuracy: 0.8335\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4078 - accuracy: 0.8354\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4075 - accuracy: 0.8349\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4072 - accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4068 - accuracy: 0.8340\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4067 - accuracy: 0.8351\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4062 - accuracy: 0.8354\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4057 - accuracy: 0.8360\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4060 - accuracy: 0.8356\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4053 - accuracy: 0.8361\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4052 - accuracy: 0.8349\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 94us/step - loss: 0.4051 - accuracy: 0.8353\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 93us/step - loss: 0.4049 - accuracy: 0.8349\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4049 - accuracy: 0.8358\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4044 - accuracy: 0.8353\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4046 - accuracy: 0.8358\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4042 - accuracy: 0.8347\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4040 - accuracy: 0.8353\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4038 - accuracy: 0.8347\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4037 - accuracy: 0.8351\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4035 - accuracy: 0.8363\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 95us/step - loss: 0.4034 - accuracy: 0.8357\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 92us/step - loss: 0.4033 - accuracy: 0.8349\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 92us/step - loss: 0.4030 - accuracy: 0.8350\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 92us/step - loss: 0.4032 - accuracy: 0.8353\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 91us/step - loss: 0.4030 - accuracy: 0.8349\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 92us/step - loss: 0.4031 - accuracy: 0.8353\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 94us/step - loss: 0.4029 - accuracy: 0.8358\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4030 - accuracy: 0.8347\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4028 - accuracy: 0.8347\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4025 - accuracy: 0.8349\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4026 - accuracy: 0.8356\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4024 - accuracy: 0.8357\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4023 - accuracy: 0.8358\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4026 - accuracy: 0.8342\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4023 - accuracy: 0.8347\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 92us/step - loss: 0.4023 - accuracy: 0.8353\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 94us/step - loss: 0.4023 - accuracy: 0.8357\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 91us/step - loss: 0.4024 - accuracy: 0.8360\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4020 - accuracy: 0.8350\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4021 - accuracy: 0.8356\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4022 - accuracy: 0.8356\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4020 - accuracy: 0.8357\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4019 - accuracy: 0.8350\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4019 - accuracy: 0.8342\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4019 - accuracy: 0.8356\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4020 - accuracy: 0.8363\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4016 - accuracy: 0.8356\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4017 - accuracy: 0.8350\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4018 - accuracy: 0.8356\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4017 - accuracy: 0.8350\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4017 - accuracy: 0.8357\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4015 - accuracy: 0.8346\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4014 - accuracy: 0.8358\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4015 - accuracy: 0.8349\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4018 - accuracy: 0.8353\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4017 - accuracy: 0.8350\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4015 - accuracy: 0.8347\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4014 - accuracy: 0.8356\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4013 - accuracy: 0.8350\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4015 - accuracy: 0.8351\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 95us/step - loss: 0.4013 - accuracy: 0.8344\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4013 - accuracy: 0.8347\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4012 - accuracy: 0.8357\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4012 - accuracy: 0.8351\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4015 - accuracy: 0.8356\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4012 - accuracy: 0.8344\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4012 - accuracy: 0.8354\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4014 - accuracy: 0.8347\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4013 - accuracy: 0.8358\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4012 - accuracy: 0.8346\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4011 - accuracy: 0.8350\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4011 - accuracy: 0.8343\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4007 - accuracy: 0.8353\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4010 - accuracy: 0.8343\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4010 - accuracy: 0.8347\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.5406 - accuracy: 0.7967\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4329 - accuracy: 0.7967\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4274 - accuracy: 0.7967\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4240 - accuracy: 0.7967\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4207 - accuracy: 0.7967\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4190 - accuracy: 0.8178\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4171 - accuracy: 0.8219\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4160 - accuracy: 0.8260\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4146 - accuracy: 0.8288\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4134 - accuracy: 0.8307\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4128 - accuracy: 0.8308\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4119 - accuracy: 0.8318\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4110 - accuracy: 0.8322\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4105 - accuracy: 0.8324\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4096 - accuracy: 0.8315\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4091 - accuracy: 0.8332\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4086 - accuracy: 0.8338\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4083 - accuracy: 0.8338\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4074 - accuracy: 0.8338\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4071 - accuracy: 0.8340\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4069 - accuracy: 0.8336\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4065 - accuracy: 0.8339\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4064 - accuracy: 0.8331\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4059 - accuracy: 0.8339\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4054 - accuracy: 0.8339\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4050 - accuracy: 0.8343\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4050 - accuracy: 0.8342\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4048 - accuracy: 0.8340\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4048 - accuracy: 0.8340\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4038 - accuracy: 0.8349\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4042 - accuracy: 0.8358\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4040 - accuracy: 0.8342\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4035 - accuracy: 0.8347\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4036 - accuracy: 0.8354\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4034 - accuracy: 0.8349\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4030 - accuracy: 0.8354\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4033 - accuracy: 0.8344\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4031 - accuracy: 0.8361\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4026 - accuracy: 0.8351\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4022 - accuracy: 0.8354\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4023 - accuracy: 0.8351\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4024 - accuracy: 0.8354\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4020 - accuracy: 0.8356\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4018 - accuracy: 0.8354\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4019 - accuracy: 0.8349\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4017 - accuracy: 0.8354\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4019 - accuracy: 0.8351\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4018 - accuracy: 0.8347\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4017 - accuracy: 0.8360\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.4019 - accuracy: 0.8354\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.4015 - accuracy: 0.8354\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4016 - accuracy: 0.8347\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 94us/step - loss: 0.4016 - accuracy: 0.8344\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4015 - accuracy: 0.8347\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4014 - accuracy: 0.8353\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4009 - accuracy: 0.8364\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4008 - accuracy: 0.8360\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4010 - accuracy: 0.8356\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4008 - accuracy: 0.8358\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4008 - accuracy: 0.8360\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4009 - accuracy: 0.8354\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4008 - accuracy: 0.8358\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4011 - accuracy: 0.8351\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4008 - accuracy: 0.8354\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4003 - accuracy: 0.8363\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4010 - accuracy: 0.8356\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 160us/step - loss: 0.4004 - accuracy: 0.8365\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.4008 - accuracy: 0.8364\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4008 - accuracy: 0.8369\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4007 - accuracy: 0.8357\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 160us/step - loss: 0.4005 - accuracy: 0.8360\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4008 - accuracy: 0.8357\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4003 - accuracy: 0.8353\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4003 - accuracy: 0.8343\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4002 - accuracy: 0.8367\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4006 - accuracy: 0.8356\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4001 - accuracy: 0.8363\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 95us/step - loss: 0.4001 - accuracy: 0.8353\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 96us/step - loss: 0.4006 - accuracy: 0.8357\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4000 - accuracy: 0.8360\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4003 - accuracy: 0.8361\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4002 - accuracy: 0.8363\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3997 - accuracy: 0.8360\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4001 - accuracy: 0.8374\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4001 - accuracy: 0.8354\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4002 - accuracy: 0.8375\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4000 - accuracy: 0.8358\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4000 - accuracy: 0.8363\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3998 - accuracy: 0.8364\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3996 - accuracy: 0.8365\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3998 - accuracy: 0.8364\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.3994 - accuracy: 0.8358\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3997 - accuracy: 0.8379\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3995 - accuracy: 0.8369\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3993 - accuracy: 0.8367\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.3994 - accuracy: 0.8374\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3998 - accuracy: 0.8354\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3999 - accuracy: 0.8375\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3994 - accuracy: 0.8353\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3999 - accuracy: 0.8363\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.5706 - accuracy: 0.7950\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4366 - accuracy: 0.7956\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4301 - accuracy: 0.7956\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4272 - accuracy: 0.7956\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4249 - accuracy: 0.7956\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4228 - accuracy: 0.7956\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4208 - accuracy: 0.7987\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4196 - accuracy: 0.8196\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4183 - accuracy: 0.8215\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4176 - accuracy: 0.8217\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4166 - accuracy: 0.8251\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4156 - accuracy: 0.8261\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4150 - accuracy: 0.8278\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4137 - accuracy: 0.8267\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4134 - accuracy: 0.8283\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4124 - accuracy: 0.8286\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4115 - accuracy: 0.8310\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4111 - accuracy: 0.8315\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4107 - accuracy: 0.8336\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4102 - accuracy: 0.8328\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4095 - accuracy: 0.8325\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4090 - accuracy: 0.8336\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4086 - accuracy: 0.8332\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4084 - accuracy: 0.8328\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4082 - accuracy: 0.8319\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4076 - accuracy: 0.8332\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4071 - accuracy: 0.8353\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4070 - accuracy: 0.8336\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4065 - accuracy: 0.8353\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4063 - accuracy: 0.8336\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4065 - accuracy: 0.8344\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4061 - accuracy: 0.8331\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4058 - accuracy: 0.8328\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4056 - accuracy: 0.8350\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4053 - accuracy: 0.8338\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4051 - accuracy: 0.8350\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4049 - accuracy: 0.8338\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4049 - accuracy: 0.8343\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4046 - accuracy: 0.8349\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4044 - accuracy: 0.8356\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4040 - accuracy: 0.8343\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4041 - accuracy: 0.8365\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4040 - accuracy: 0.8354\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4039 - accuracy: 0.8357\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4037 - accuracy: 0.8351\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4034 - accuracy: 0.8346\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4030 - accuracy: 0.8342\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4031 - accuracy: 0.8358\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4027 - accuracy: 0.8349\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4032 - accuracy: 0.8349\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4024 - accuracy: 0.8344\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4030 - accuracy: 0.8364\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4025 - accuracy: 0.8349\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4027 - accuracy: 0.8360\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4023 - accuracy: 0.8343\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4025 - accuracy: 0.8349\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4023 - accuracy: 0.8339\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4022 - accuracy: 0.8351\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4021 - accuracy: 0.8360\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4022 - accuracy: 0.8354\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4020 - accuracy: 0.8346\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4020 - accuracy: 0.8353\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4022 - accuracy: 0.8350\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4020 - accuracy: 0.8344\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4018 - accuracy: 0.8347\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4018 - accuracy: 0.8353\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4016 - accuracy: 0.8346\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4016 - accuracy: 0.8364\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4016 - accuracy: 0.8347\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4017 - accuracy: 0.8356\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4017 - accuracy: 0.8365\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4015 - accuracy: 0.8353\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4015 - accuracy: 0.8346\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4015 - accuracy: 0.8364\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4013 - accuracy: 0.8372\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4014 - accuracy: 0.8347\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4015 - accuracy: 0.8364\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4012 - accuracy: 0.8354\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4007 - accuracy: 0.8346\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4011 - accuracy: 0.8363\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4009 - accuracy: 0.8365\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4011 - accuracy: 0.8360\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4010 - accuracy: 0.8350\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4009 - accuracy: 0.8344\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4008 - accuracy: 0.8351\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4008 - accuracy: 0.8342\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4011 - accuracy: 0.8343\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4008 - accuracy: 0.8349\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4009 - accuracy: 0.8350\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4006 - accuracy: 0.8367\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4006 - accuracy: 0.8347\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4004 - accuracy: 0.8360\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4005 - accuracy: 0.8350\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4011 - accuracy: 0.8364\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4010 - accuracy: 0.8365\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4004 - accuracy: 0.8342\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4004 - accuracy: 0.8369\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.4007 - accuracy: 0.8346\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4005 - accuracy: 0.8358\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4005 - accuracy: 0.8353\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.5539 - accuracy: 0.7971\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4339 - accuracy: 0.7975\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4278 - accuracy: 0.7975\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4249 - accuracy: 0.7975\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4216 - accuracy: 0.7975\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4184 - accuracy: 0.7975\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4161 - accuracy: 0.8188\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4145 - accuracy: 0.8246\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4131 - accuracy: 0.8263\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4119 - accuracy: 0.8303\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4110 - accuracy: 0.8317\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4105 - accuracy: 0.8321\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4092 - accuracy: 0.8331\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4086 - accuracy: 0.8342\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4079 - accuracy: 0.8333\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4070 - accuracy: 0.8335\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4063 - accuracy: 0.8347\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4060 - accuracy: 0.8343\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4051 - accuracy: 0.8349\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4047 - accuracy: 0.8349\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4040 - accuracy: 0.8342\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4037 - accuracy: 0.8363\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4032 - accuracy: 0.8356\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4032 - accuracy: 0.8364\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4028 - accuracy: 0.8354\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4026 - accuracy: 0.8357\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4023 - accuracy: 0.8369\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4018 - accuracy: 0.8358\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4013 - accuracy: 0.8346\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4014 - accuracy: 0.8356\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4010 - accuracy: 0.8360\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4008 - accuracy: 0.8358\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4011 - accuracy: 0.8346\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4007 - accuracy: 0.8363\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4004 - accuracy: 0.8365\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4006 - accuracy: 0.8364\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4001 - accuracy: 0.8361\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4000 - accuracy: 0.8367\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3994 - accuracy: 0.8354\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3993 - accuracy: 0.8369\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.3994 - accuracy: 0.8358\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.3997 - accuracy: 0.8364\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.3995 - accuracy: 0.8360\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3990 - accuracy: 0.8356\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3991 - accuracy: 0.8371\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.3993 - accuracy: 0.8357\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3992 - accuracy: 0.8356\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3989 - accuracy: 0.8371\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3989 - accuracy: 0.8349\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3986 - accuracy: 0.8365\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3987 - accuracy: 0.8354\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3983 - accuracy: 0.8357\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3984 - accuracy: 0.8368\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3985 - accuracy: 0.8358\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3981 - accuracy: 0.8382\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3980 - accuracy: 0.8375\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3980 - accuracy: 0.8367\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3979 - accuracy: 0.8367\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3982 - accuracy: 0.8354\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3979 - accuracy: 0.8365\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3980 - accuracy: 0.8367\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3977 - accuracy: 0.8364\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3981 - accuracy: 0.8369\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3977 - accuracy: 0.8368\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3974 - accuracy: 0.8369\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.3979 - accuracy: 0.8364\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3979 - accuracy: 0.8375\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.3977 - accuracy: 0.8365\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.3975 - accuracy: 0.8363\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.3975 - accuracy: 0.8371\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.3974 - accuracy: 0.8374\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3976 - accuracy: 0.8367\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.3976 - accuracy: 0.8371\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3974 - accuracy: 0.8357\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3975 - accuracy: 0.8365\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.3972 - accuracy: 0.8369\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.3969 - accuracy: 0.8357\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3972 - accuracy: 0.8358\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3973 - accuracy: 0.8378\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3971 - accuracy: 0.8357\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.3975 - accuracy: 0.8371\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.3972 - accuracy: 0.8367\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.3969 - accuracy: 0.8361\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.3968 - accuracy: 0.8364\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3970 - accuracy: 0.8363\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3970 - accuracy: 0.8361\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3968 - accuracy: 0.8361\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3973 - accuracy: 0.8369\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.3970 - accuracy: 0.8365\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3971 - accuracy: 0.8353\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 157us/step - loss: 0.3970 - accuracy: 0.8375\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3966 - accuracy: 0.8357\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3974 - accuracy: 0.8367\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3969 - accuracy: 0.8354\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.3972 - accuracy: 0.8356\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3972 - accuracy: 0.8365\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3970 - accuracy: 0.8375\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3970 - accuracy: 0.8374\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3974 - accuracy: 0.8340\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3973 - accuracy: 0.8376\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 156us/step - loss: 0.5694 - accuracy: 0.7925\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4417 - accuracy: 0.7937\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4351 - accuracy: 0.7937\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4327 - accuracy: 0.7937\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4302 - accuracy: 0.7937\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4278 - accuracy: 0.7937\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4253 - accuracy: 0.7937\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4231 - accuracy: 0.8151\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4218 - accuracy: 0.8186\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4202 - accuracy: 0.8226\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4191 - accuracy: 0.8231\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4184 - accuracy: 0.8247\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4176 - accuracy: 0.8244\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4165 - accuracy: 0.8279\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4157 - accuracy: 0.8289\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4149 - accuracy: 0.8289\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4147 - accuracy: 0.8307\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4139 - accuracy: 0.8306\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4133 - accuracy: 0.8311\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4128 - accuracy: 0.8321\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4126 - accuracy: 0.8324\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4120 - accuracy: 0.8318\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4119 - accuracy: 0.8321\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4110 - accuracy: 0.8308\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4109 - accuracy: 0.8321\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4103 - accuracy: 0.8326\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4100 - accuracy: 0.8325\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4098 - accuracy: 0.8324\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4093 - accuracy: 0.8325\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4088 - accuracy: 0.8315\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4081 - accuracy: 0.8336\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4086 - accuracy: 0.8315\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4081 - accuracy: 0.8346\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4076 - accuracy: 0.8332\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4073 - accuracy: 0.8326\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4072 - accuracy: 0.8335\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4073 - accuracy: 0.8335\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4067 - accuracy: 0.8329\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4066 - accuracy: 0.8329\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4063 - accuracy: 0.8325\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4061 - accuracy: 0.8335\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4061 - accuracy: 0.8310\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4057 - accuracy: 0.8332\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4055 - accuracy: 0.8324\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4054 - accuracy: 0.8325\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4053 - accuracy: 0.8322\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4051 - accuracy: 0.8331\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4049 - accuracy: 0.8331\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4045 - accuracy: 0.8313\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4050 - accuracy: 0.8317\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4045 - accuracy: 0.8329\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 173us/step - loss: 0.4045 - accuracy: 0.8322\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4048 - accuracy: 0.8331\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4040 - accuracy: 0.8321\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4046 - accuracy: 0.8321\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4043 - accuracy: 0.8317\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4041 - accuracy: 0.8324\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4043 - accuracy: 0.8324\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4041 - accuracy: 0.8326\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4040 - accuracy: 0.8322\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4039 - accuracy: 0.8333\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4041 - accuracy: 0.8319\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4040 - accuracy: 0.8326\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4038 - accuracy: 0.8333\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4037 - accuracy: 0.8332\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4037 - accuracy: 0.8325\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4037 - accuracy: 0.8338\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4033 - accuracy: 0.8332\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4035 - accuracy: 0.8326\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4037 - accuracy: 0.8322\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4033 - accuracy: 0.8333\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4037 - accuracy: 0.8326\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4035 - accuracy: 0.8339\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4037 - accuracy: 0.8328\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4031 - accuracy: 0.8318\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4036 - accuracy: 0.8326\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4033 - accuracy: 0.8332\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4030 - accuracy: 0.8319\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4033 - accuracy: 0.8335\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4032 - accuracy: 0.8314\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4033 - accuracy: 0.8335\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4034 - accuracy: 0.8329\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4034 - accuracy: 0.8331\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4030 - accuracy: 0.8324\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4033 - accuracy: 0.8332\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4030 - accuracy: 0.8332\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4027 - accuracy: 0.8338\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4031 - accuracy: 0.8318\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4031 - accuracy: 0.8332\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4027 - accuracy: 0.8317\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4032 - accuracy: 0.8332\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 98us/step - loss: 0.4027 - accuracy: 0.8325\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 99us/step - loss: 0.4028 - accuracy: 0.8328\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4029 - accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4032 - accuracy: 0.8329\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4028 - accuracy: 0.8317\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4026 - accuracy: 0.8333\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4027 - accuracy: 0.8329\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4027 - accuracy: 0.8338\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4026 - accuracy: 0.8340\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 175us/step - loss: 0.5566 - accuracy: 0.7935\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4376 - accuracy: 0.7944\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4315 - accuracy: 0.7944\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4291 - accuracy: 0.7944\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4272 - accuracy: 0.7944\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4244 - accuracy: 0.7956\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4219 - accuracy: 0.8122\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4202 - accuracy: 0.8186\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4185 - accuracy: 0.8240\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4171 - accuracy: 0.8249\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4156 - accuracy: 0.8276\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4145 - accuracy: 0.8288\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4132 - accuracy: 0.8306\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4118 - accuracy: 0.8310\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4110 - accuracy: 0.8324\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4104 - accuracy: 0.8340\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4096 - accuracy: 0.8343\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4089 - accuracy: 0.8344\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4082 - accuracy: 0.8338\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4074 - accuracy: 0.8351\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4072 - accuracy: 0.8347\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4068 - accuracy: 0.8347\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4059 - accuracy: 0.8347\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4052 - accuracy: 0.8349\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4050 - accuracy: 0.8349\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4049 - accuracy: 0.8340\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4044 - accuracy: 0.8356\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4044 - accuracy: 0.8344\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 2s 223us/step - loss: 0.4034 - accuracy: 0.8360\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 2s 229us/step - loss: 0.4040 - accuracy: 0.8340\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 2s 261us/step - loss: 0.4037 - accuracy: 0.8361\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4029 - accuracy: 0.8349\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4029 - accuracy: 0.8340\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4026 - accuracy: 0.8354\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4024 - accuracy: 0.8339\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4024 - accuracy: 0.8346\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4023 - accuracy: 0.8343\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4024 - accuracy: 0.8351\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4019 - accuracy: 0.8358\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4021 - accuracy: 0.8353\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 101us/step - loss: 0.4017 - accuracy: 0.8331\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4014 - accuracy: 0.8353\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4015 - accuracy: 0.8344\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4013 - accuracy: 0.8326\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4013 - accuracy: 0.8354\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4012 - accuracy: 0.8340\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 100us/step - loss: 0.4010 - accuracy: 0.8344\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4010 - accuracy: 0.8344\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4010 - accuracy: 0.8346\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4009 - accuracy: 0.8331\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 102us/step - loss: 0.4009 - accuracy: 0.8354\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4009 - accuracy: 0.8350\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4009 - accuracy: 0.8353\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4007 - accuracy: 0.8358\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4005 - accuracy: 0.8342\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4004 - accuracy: 0.8344\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4007 - accuracy: 0.8351\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 166us/step - loss: 0.4006 - accuracy: 0.8347\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4004 - accuracy: 0.8338\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.4002 - accuracy: 0.8351\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4006 - accuracy: 0.8346\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4002 - accuracy: 0.8354\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4005 - accuracy: 0.8351\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4005 - accuracy: 0.8349\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4001 - accuracy: 0.8343\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4000 - accuracy: 0.8347\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4003 - accuracy: 0.8347\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4004 - accuracy: 0.8353\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3995 - accuracy: 0.8369\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4000 - accuracy: 0.8357\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3999 - accuracy: 0.8343\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.4001 - accuracy: 0.8332\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4001 - accuracy: 0.8343\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 153us/step - loss: 0.3998 - accuracy: 0.8351\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3995 - accuracy: 0.8353\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4001 - accuracy: 0.8346\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3996 - accuracy: 0.8344\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4000 - accuracy: 0.8356\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3998 - accuracy: 0.8346\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.3996 - accuracy: 0.8349\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3994 - accuracy: 0.8347\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4003 - accuracy: 0.8343\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3994 - accuracy: 0.8344\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3993 - accuracy: 0.8350\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3994 - accuracy: 0.8344\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.3994 - accuracy: 0.8349\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3996 - accuracy: 0.8346\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3995 - accuracy: 0.8343\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3996 - accuracy: 0.8347\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3999 - accuracy: 0.8356\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3994 - accuracy: 0.8354\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3991 - accuracy: 0.8357\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3996 - accuracy: 0.8339\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3994 - accuracy: 0.8349\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3998 - accuracy: 0.8338\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3993 - accuracy: 0.8344\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3991 - accuracy: 0.8347\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3994 - accuracy: 0.8344\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3994 - accuracy: 0.8357\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3996 - accuracy: 0.8350\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 191us/step - loss: 0.5769 - accuracy: 0.7969\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4378 - accuracy: 0.7969\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 166us/step - loss: 0.4294 - accuracy: 0.7969\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4250 - accuracy: 0.7969\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4216 - accuracy: 0.8039\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4183 - accuracy: 0.8229\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4158 - accuracy: 0.8264\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4130 - accuracy: 0.8306\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4104 - accuracy: 0.8328\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4084 - accuracy: 0.8326\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4066 - accuracy: 0.8332\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4054 - accuracy: 0.8363\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4045 - accuracy: 0.8361\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4038 - accuracy: 0.8356\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4028 - accuracy: 0.8358\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4021 - accuracy: 0.8361\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4018 - accuracy: 0.8349\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4005 - accuracy: 0.8357\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4003 - accuracy: 0.8350\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3999 - accuracy: 0.8349\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3991 - accuracy: 0.8357\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3982 - accuracy: 0.8354\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3982 - accuracy: 0.8349\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3979 - accuracy: 0.8357\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3973 - accuracy: 0.8349\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3972 - accuracy: 0.8357\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.3968 - accuracy: 0.8354\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3965 - accuracy: 0.8350\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3964 - accuracy: 0.8349\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3958 - accuracy: 0.8354\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3962 - accuracy: 0.8350\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3958 - accuracy: 0.8356\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3956 - accuracy: 0.8363\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3956 - accuracy: 0.8365\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3952 - accuracy: 0.8360\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3952 - accuracy: 0.8351\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3947 - accuracy: 0.8374\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3945 - accuracy: 0.8361\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3951 - accuracy: 0.8356\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3947 - accuracy: 0.8361\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3945 - accuracy: 0.8365\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3944 - accuracy: 0.8361\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3941 - accuracy: 0.8350\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 162us/step - loss: 0.3941 - accuracy: 0.8349\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3941 - accuracy: 0.8357\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3936 - accuracy: 0.8367\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3934 - accuracy: 0.8368\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3936 - accuracy: 0.8365\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3933 - accuracy: 0.8351\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3933 - accuracy: 0.8363\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3928 - accuracy: 0.8371\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3930 - accuracy: 0.8369\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3921 - accuracy: 0.8361\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3921 - accuracy: 0.8372\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3918 - accuracy: 0.8351\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3910 - accuracy: 0.8382\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3901 - accuracy: 0.8396\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3900 - accuracy: 0.8399\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3890 - accuracy: 0.8392\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3885 - accuracy: 0.8406\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3876 - accuracy: 0.8404\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3861 - accuracy: 0.8413\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3855 - accuracy: 0.8407\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3838 - accuracy: 0.8419\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3817 - accuracy: 0.8432\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3798 - accuracy: 0.8431\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3781 - accuracy: 0.8440\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3756 - accuracy: 0.8443\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3738 - accuracy: 0.8461\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3716 - accuracy: 0.8440\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3692 - accuracy: 0.8481\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3665 - accuracy: 0.8490\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3626 - accuracy: 0.8478\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3606 - accuracy: 0.8524\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3580 - accuracy: 0.8536\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3573 - accuracy: 0.8521\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3562 - accuracy: 0.8535\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3542 - accuracy: 0.8558\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3529 - accuracy: 0.8564\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3526 - accuracy: 0.8554\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3510 - accuracy: 0.8547\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3503 - accuracy: 0.8579\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3506 - accuracy: 0.8561\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3488 - accuracy: 0.8579\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3480 - accuracy: 0.8567\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3479 - accuracy: 0.8579\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3471 - accuracy: 0.8571\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3469 - accuracy: 0.8574\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3469 - accuracy: 0.8585\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3461 - accuracy: 0.8597\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3458 - accuracy: 0.8594\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3450 - accuracy: 0.8594\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3456 - accuracy: 0.8578\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3448 - accuracy: 0.8593\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3446 - accuracy: 0.8590\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3442 - accuracy: 0.8611\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3428 - accuracy: 0.8597\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3439 - accuracy: 0.8579\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3436 - accuracy: 0.8583\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3434 - accuracy: 0.8594\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 189us/step - loss: 0.5732 - accuracy: 0.7960\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4378 - accuracy: 0.7962\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4304 - accuracy: 0.7962\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4254 - accuracy: 0.7962\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4189 - accuracy: 0.8092\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4133 - accuracy: 0.8310\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4100 - accuracy: 0.8342\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4067 - accuracy: 0.8361\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4044 - accuracy: 0.8350\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4026 - accuracy: 0.8350\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4016 - accuracy: 0.8351\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4006 - accuracy: 0.8350\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4000 - accuracy: 0.8353\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3987 - accuracy: 0.8339\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3984 - accuracy: 0.8350\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3977 - accuracy: 0.8347\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3973 - accuracy: 0.8343\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3968 - accuracy: 0.8354\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3965 - accuracy: 0.8360\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3963 - accuracy: 0.8351\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3959 - accuracy: 0.8354\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 167us/step - loss: 0.3958 - accuracy: 0.8350\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 174us/step - loss: 0.3956 - accuracy: 0.8382\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 160us/step - loss: 0.3953 - accuracy: 0.8356\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 170us/step - loss: 0.3951 - accuracy: 0.8353\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 162us/step - loss: 0.3951 - accuracy: 0.8347\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.3949 - accuracy: 0.8356\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3946 - accuracy: 0.8360\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 153us/step - loss: 0.3945 - accuracy: 0.8358\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3946 - accuracy: 0.8358\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3943 - accuracy: 0.8361\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3944 - accuracy: 0.8350\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3939 - accuracy: 0.8374\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 175us/step - loss: 0.3942 - accuracy: 0.8378\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3943 - accuracy: 0.8365\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3937 - accuracy: 0.8375\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3936 - accuracy: 0.8367\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3937 - accuracy: 0.8382\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3934 - accuracy: 0.8374\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3932 - accuracy: 0.8378\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3927 - accuracy: 0.8374\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3931 - accuracy: 0.8375\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3929 - accuracy: 0.8367\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3924 - accuracy: 0.8379\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3922 - accuracy: 0.8385\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3915 - accuracy: 0.8365\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3912 - accuracy: 0.8386\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3902 - accuracy: 0.8379\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3892 - accuracy: 0.8383\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3882 - accuracy: 0.8401\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3865 - accuracy: 0.8397\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3848 - accuracy: 0.8392\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3837 - accuracy: 0.8403\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3820 - accuracy: 0.8406\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3799 - accuracy: 0.8413\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3786 - accuracy: 0.8410\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3770 - accuracy: 0.8410\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3752 - accuracy: 0.8397\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3735 - accuracy: 0.8407\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3726 - accuracy: 0.8383\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3706 - accuracy: 0.8403\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3702 - accuracy: 0.8376\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3688 - accuracy: 0.8419\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3679 - accuracy: 0.8414\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3669 - accuracy: 0.8415\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3657 - accuracy: 0.8411\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3641 - accuracy: 0.8444\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3634 - accuracy: 0.8449\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3622 - accuracy: 0.8471\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3607 - accuracy: 0.8507\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3597 - accuracy: 0.8475\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3592 - accuracy: 0.8504\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3572 - accuracy: 0.8525\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3565 - accuracy: 0.8532\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3559 - accuracy: 0.8544\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3540 - accuracy: 0.8579\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3534 - accuracy: 0.8581\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3528 - accuracy: 0.8596\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3516 - accuracy: 0.8599\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3511 - accuracy: 0.8576\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3502 - accuracy: 0.8615\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3495 - accuracy: 0.8578\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3486 - accuracy: 0.8625\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3486 - accuracy: 0.8628\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3482 - accuracy: 0.8617\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3476 - accuracy: 0.8636\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3470 - accuracy: 0.8607\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3469 - accuracy: 0.8618\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3464 - accuracy: 0.8647\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.3461 - accuracy: 0.8643\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3459 - accuracy: 0.8633\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3461 - accuracy: 0.8631\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3450 - accuracy: 0.8637\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3458 - accuracy: 0.8629\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3444 - accuracy: 0.8624\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3445 - accuracy: 0.8629\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3443 - accuracy: 0.8626\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3442 - accuracy: 0.8628\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3444 - accuracy: 0.8619\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3439 - accuracy: 0.8643\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 175us/step - loss: 0.5576 - accuracy: 0.7956\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4355 - accuracy: 0.7957\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4293 - accuracy: 0.7957\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4267 - accuracy: 0.7957\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4254 - accuracy: 0.7957\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4236 - accuracy: 0.7957\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4217 - accuracy: 0.7957\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4195 - accuracy: 0.8056\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4177 - accuracy: 0.8200\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4159 - accuracy: 0.8249\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4143 - accuracy: 0.8265\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4127 - accuracy: 0.8288\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4114 - accuracy: 0.8315\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4104 - accuracy: 0.8338\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4094 - accuracy: 0.8340\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4086 - accuracy: 0.8340\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4081 - accuracy: 0.8340\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4069 - accuracy: 0.8361\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4064 - accuracy: 0.8354\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4058 - accuracy: 0.8363\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4052 - accuracy: 0.8367\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4046 - accuracy: 0.8357\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4039 - accuracy: 0.8368\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4037 - accuracy: 0.8363\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4036 - accuracy: 0.8375\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4028 - accuracy: 0.8368\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4029 - accuracy: 0.8367\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4019 - accuracy: 0.8358\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4021 - accuracy: 0.8367\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4016 - accuracy: 0.8372\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4014 - accuracy: 0.8378\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4011 - accuracy: 0.8364\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4010 - accuracy: 0.8368\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4008 - accuracy: 0.8368\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4005 - accuracy: 0.8379\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4001 - accuracy: 0.8365\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4003 - accuracy: 0.8375\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4000 - accuracy: 0.8368\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3997 - accuracy: 0.8372\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3997 - accuracy: 0.8361\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3995 - accuracy: 0.8374\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3993 - accuracy: 0.8374\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3989 - accuracy: 0.8367\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3995 - accuracy: 0.8356\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3991 - accuracy: 0.8364\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3990 - accuracy: 0.8365\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3989 - accuracy: 0.8363\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3987 - accuracy: 0.8368\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3988 - accuracy: 0.8363\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3986 - accuracy: 0.8365\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3986 - accuracy: 0.8367\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3983 - accuracy: 0.8357\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3985 - accuracy: 0.8354\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3981 - accuracy: 0.8382\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3981 - accuracy: 0.8360\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3981 - accuracy: 0.8367\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3981 - accuracy: 0.8363\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3979 - accuracy: 0.8376\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3980 - accuracy: 0.8361\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3980 - accuracy: 0.8357\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3978 - accuracy: 0.8361\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3981 - accuracy: 0.8371\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3979 - accuracy: 0.8364\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3978 - accuracy: 0.8369\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3981 - accuracy: 0.8357\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.3976 - accuracy: 0.8365\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3979 - accuracy: 0.8375\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 202us/step - loss: 0.3977 - accuracy: 0.8361\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3978 - accuracy: 0.8365\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3976 - accuracy: 0.8368\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3971 - accuracy: 0.8371\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3975 - accuracy: 0.8374\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3977 - accuracy: 0.8367\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3975 - accuracy: 0.8363\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3972 - accuracy: 0.8372\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3974 - accuracy: 0.8356\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3972 - accuracy: 0.8375\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3974 - accuracy: 0.8371\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3975 - accuracy: 0.8375\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3973 - accuracy: 0.8374\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3976 - accuracy: 0.8367\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3974 - accuracy: 0.8375\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3972 - accuracy: 0.8369\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3971 - accuracy: 0.8379\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3975 - accuracy: 0.8367\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3970 - accuracy: 0.8369\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3971 - accuracy: 0.8364\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3970 - accuracy: 0.8368\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3973 - accuracy: 0.8360\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.3970 - accuracy: 0.8356\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3970 - accuracy: 0.8368\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3972 - accuracy: 0.8372\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3965 - accuracy: 0.8382\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3973 - accuracy: 0.8361\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3970 - accuracy: 0.8360\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3964 - accuracy: 0.8381\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3971 - accuracy: 0.8353\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3971 - accuracy: 0.8365\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3971 - accuracy: 0.8354\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3971 - accuracy: 0.8371\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 181us/step - loss: 0.5809 - accuracy: 0.7943\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4391 - accuracy: 0.7961\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4313 - accuracy: 0.7961\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4277 - accuracy: 0.7961\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4243 - accuracy: 0.7985\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4214 - accuracy: 0.8193\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 165us/step - loss: 0.4184 - accuracy: 0.8250\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4154 - accuracy: 0.8272\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4132 - accuracy: 0.8286\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4112 - accuracy: 0.8301\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4093 - accuracy: 0.8317\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4078 - accuracy: 0.8326\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4069 - accuracy: 0.8335\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4055 - accuracy: 0.8338\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4049 - accuracy: 0.8342\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4039 - accuracy: 0.8351\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4031 - accuracy: 0.8346\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4022 - accuracy: 0.8340\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4017 - accuracy: 0.8339\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4011 - accuracy: 0.8332\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4003 - accuracy: 0.8347\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4000 - accuracy: 0.8349\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3998 - accuracy: 0.8333\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3995 - accuracy: 0.8340\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3986 - accuracy: 0.8350\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3988 - accuracy: 0.8340\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3987 - accuracy: 0.8340\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3981 - accuracy: 0.8340\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3982 - accuracy: 0.8346\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3977 - accuracy: 0.8349\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3974 - accuracy: 0.8349\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3974 - accuracy: 0.8353\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3971 - accuracy: 0.8346\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3973 - accuracy: 0.8349\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3969 - accuracy: 0.8354\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3967 - accuracy: 0.8354\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3967 - accuracy: 0.8351\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3966 - accuracy: 0.8354\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3968 - accuracy: 0.8365\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3963 - accuracy: 0.8351\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3966 - accuracy: 0.8349\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3961 - accuracy: 0.8351\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3962 - accuracy: 0.8344\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3961 - accuracy: 0.8372\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3959 - accuracy: 0.8344\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3957 - accuracy: 0.8365\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3957 - accuracy: 0.8365\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3958 - accuracy: 0.8350\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3957 - accuracy: 0.8361\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3956 - accuracy: 0.8344\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3952 - accuracy: 0.8369\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3950 - accuracy: 0.8375\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3958 - accuracy: 0.8354\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 164us/step - loss: 0.3956 - accuracy: 0.8350\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3956 - accuracy: 0.8346\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3954 - accuracy: 0.8353\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.3949 - accuracy: 0.8371\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3953 - accuracy: 0.8361\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 185us/step - loss: 0.3954 - accuracy: 0.8360\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.3954 - accuracy: 0.8367\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3952 - accuracy: 0.8347\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3951 - accuracy: 0.8369\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 164us/step - loss: 0.3949 - accuracy: 0.8350\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.3948 - accuracy: 0.8361\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3946 - accuracy: 0.8371\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 156us/step - loss: 0.3951 - accuracy: 0.8364\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.3942 - accuracy: 0.8368\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.3945 - accuracy: 0.8361\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.3947 - accuracy: 0.8376\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 195us/step - loss: 0.3946 - accuracy: 0.8350\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 161us/step - loss: 0.3944 - accuracy: 0.8340\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.3944 - accuracy: 0.8363\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3944 - accuracy: 0.8357\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3945 - accuracy: 0.8371\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3944 - accuracy: 0.8378\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3940 - accuracy: 0.8368\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3943 - accuracy: 0.8383\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3943 - accuracy: 0.8363\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3941 - accuracy: 0.8340\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3941 - accuracy: 0.8367\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3941 - accuracy: 0.8376\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.3942 - accuracy: 0.8364\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 161us/step - loss: 0.3940 - accuracy: 0.8358\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3943 - accuracy: 0.8375\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3936 - accuracy: 0.8358\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3939 - accuracy: 0.8371\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3936 - accuracy: 0.8358\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3939 - accuracy: 0.8369\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3935 - accuracy: 0.8365\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3934 - accuracy: 0.8368\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3936 - accuracy: 0.8372\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3935 - accuracy: 0.8376\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3934 - accuracy: 0.8372\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3935 - accuracy: 0.8374\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3936 - accuracy: 0.8382\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3931 - accuracy: 0.8379\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3937 - accuracy: 0.8367\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3935 - accuracy: 0.8356\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3927 - accuracy: 0.8379\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3935 - accuracy: 0.8358\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 180us/step - loss: 0.5540 - accuracy: 0.7971\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4391 - accuracy: 0.7971\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4308 - accuracy: 0.7971\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4267 - accuracy: 0.7971\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4236 - accuracy: 0.7971\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4208 - accuracy: 0.7997\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4186 - accuracy: 0.8178\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4171 - accuracy: 0.8222\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4158 - accuracy: 0.8250\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4149 - accuracy: 0.8264\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4134 - accuracy: 0.8289\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4127 - accuracy: 0.8297\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4119 - accuracy: 0.8328\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4114 - accuracy: 0.8313\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4102 - accuracy: 0.8315\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4097 - accuracy: 0.8332\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4088 - accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4086 - accuracy: 0.8342\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4081 - accuracy: 0.8333\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4076 - accuracy: 0.8353\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4072 - accuracy: 0.8349\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4067 - accuracy: 0.8343\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4061 - accuracy: 0.8356\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4063 - accuracy: 0.8343\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4055 - accuracy: 0.8353\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4057 - accuracy: 0.8342\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4052 - accuracy: 0.8351\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4050 - accuracy: 0.8340\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4049 - accuracy: 0.8363\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4045 - accuracy: 0.8340\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4044 - accuracy: 0.8349\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4042 - accuracy: 0.8356\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4039 - accuracy: 0.8361\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4040 - accuracy: 0.8347\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4036 - accuracy: 0.8347\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4036 - accuracy: 0.8360\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4034 - accuracy: 0.8357\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4032 - accuracy: 0.8354\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4029 - accuracy: 0.8347\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4029 - accuracy: 0.8353\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4026 - accuracy: 0.8353\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4026 - accuracy: 0.8339\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4026 - accuracy: 0.8350\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4024 - accuracy: 0.8346\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4020 - accuracy: 0.8351\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4023 - accuracy: 0.8340\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4021 - accuracy: 0.8351\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4018 - accuracy: 0.8358\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4017 - accuracy: 0.8338\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4018 - accuracy: 0.8353\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4018 - accuracy: 0.8343\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4016 - accuracy: 0.8346\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4018 - accuracy: 0.8338\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4016 - accuracy: 0.8346\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4011 - accuracy: 0.8335\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4016 - accuracy: 0.8346\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4015 - accuracy: 0.8343\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4011 - accuracy: 0.8342\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4011 - accuracy: 0.8354\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4010 - accuracy: 0.8333\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4014 - accuracy: 0.8339\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4008 - accuracy: 0.8360\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4005 - accuracy: 0.8344\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4011 - accuracy: 0.8358\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4006 - accuracy: 0.8343\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.4008 - accuracy: 0.8342\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4010 - accuracy: 0.8321\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4009 - accuracy: 0.8339\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4005 - accuracy: 0.8335\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4008 - accuracy: 0.8340\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4004 - accuracy: 0.8338\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4008 - accuracy: 0.8331\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4005 - accuracy: 0.8346\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4009 - accuracy: 0.8347\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4000 - accuracy: 0.8338\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4006 - accuracy: 0.8340\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4005 - accuracy: 0.8335\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4005 - accuracy: 0.8340\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4006 - accuracy: 0.8339\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4007 - accuracy: 0.8329\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4002 - accuracy: 0.8331\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4003 - accuracy: 0.8338\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4004 - accuracy: 0.8329\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3999 - accuracy: 0.8333\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4001 - accuracy: 0.8349\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4001 - accuracy: 0.8328\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.4002 - accuracy: 0.8343\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4001 - accuracy: 0.8339\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4001 - accuracy: 0.8335\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4001 - accuracy: 0.8342\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4000 - accuracy: 0.8350\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3998 - accuracy: 0.8354\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4002 - accuracy: 0.8332\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3996 - accuracy: 0.8331\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3997 - accuracy: 0.8339\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3999 - accuracy: 0.8335\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3998 - accuracy: 0.8336\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3995 - accuracy: 0.8343\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3996 - accuracy: 0.8343\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3991 - accuracy: 0.8340\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 2s 216us/step - loss: 0.5720 - accuracy: 0.7960\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4401 - accuracy: 0.7967\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 190us/step - loss: 0.4306 - accuracy: 0.7967\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 188us/step - loss: 0.4268 - accuracy: 0.7967\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4234 - accuracy: 0.7967\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4206 - accuracy: 0.7967\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4179 - accuracy: 0.8154\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 161us/step - loss: 0.4164 - accuracy: 0.8243\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 172us/step - loss: 0.4150 - accuracy: 0.8257\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 159us/step - loss: 0.4141 - accuracy: 0.8292\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4129 - accuracy: 0.8304\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4125 - accuracy: 0.8322\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 171us/step - loss: 0.4114 - accuracy: 0.8328\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4109 - accuracy: 0.8324\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 173us/step - loss: 0.4096 - accuracy: 0.8324\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4096 - accuracy: 0.8317\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 171us/step - loss: 0.4088 - accuracy: 0.8324\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 177us/step - loss: 0.4084 - accuracy: 0.8343\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 164us/step - loss: 0.4076 - accuracy: 0.8338\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.4071 - accuracy: 0.8333\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4067 - accuracy: 0.8347\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4056 - accuracy: 0.8347\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4053 - accuracy: 0.8346\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4044 - accuracy: 0.8346\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4037 - accuracy: 0.8354\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4032 - accuracy: 0.8361\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4021 - accuracy: 0.8347\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4021 - accuracy: 0.8365\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4013 - accuracy: 0.8349\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4010 - accuracy: 0.8368\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4005 - accuracy: 0.8368\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4002 - accuracy: 0.8360\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3997 - accuracy: 0.8361\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3993 - accuracy: 0.8367\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3986 - accuracy: 0.8360\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3983 - accuracy: 0.8350\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3982 - accuracy: 0.8371\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3978 - accuracy: 0.8374\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3979 - accuracy: 0.8369\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3975 - accuracy: 0.8371\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3969 - accuracy: 0.8371\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3969 - accuracy: 0.8365\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3968 - accuracy: 0.8369\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3963 - accuracy: 0.8372\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3962 - accuracy: 0.8371\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3958 - accuracy: 0.8374\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3961 - accuracy: 0.8361\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3957 - accuracy: 0.8367\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3959 - accuracy: 0.8367\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3958 - accuracy: 0.8363\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3955 - accuracy: 0.8379\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3957 - accuracy: 0.8372\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3955 - accuracy: 0.8386\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3952 - accuracy: 0.8378\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3952 - accuracy: 0.8383\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3950 - accuracy: 0.8367\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3949 - accuracy: 0.8378\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3949 - accuracy: 0.8375\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3947 - accuracy: 0.8378\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3948 - accuracy: 0.8368\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3941 - accuracy: 0.8385\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3944 - accuracy: 0.8375\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3942 - accuracy: 0.8386\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3945 - accuracy: 0.8383\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3943 - accuracy: 0.8378\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3943 - accuracy: 0.8371\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3943 - accuracy: 0.8390\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3942 - accuracy: 0.8372\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3938 - accuracy: 0.8396\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.3941 - accuracy: 0.8379\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3942 - accuracy: 0.8374\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3937 - accuracy: 0.8376\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3941 - accuracy: 0.8378\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3942 - accuracy: 0.8386\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3939 - accuracy: 0.8379\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3936 - accuracy: 0.8372\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3937 - accuracy: 0.8374\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3936 - accuracy: 0.8385\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3940 - accuracy: 0.8374\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3935 - accuracy: 0.8392\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3934 - accuracy: 0.8394\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3933 - accuracy: 0.8397\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3934 - accuracy: 0.8383\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3929 - accuracy: 0.8374\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3932 - accuracy: 0.8400\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3931 - accuracy: 0.8404\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3935 - accuracy: 0.8385\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3936 - accuracy: 0.8390\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3932 - accuracy: 0.8376\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3933 - accuracy: 0.8393\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3930 - accuracy: 0.8369\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3931 - accuracy: 0.8394\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3933 - accuracy: 0.8385\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3934 - accuracy: 0.8389\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3928 - accuracy: 0.8386\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3934 - accuracy: 0.8399\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3930 - accuracy: 0.8393\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3933 - accuracy: 0.8375\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3929 - accuracy: 0.8390\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3931 - accuracy: 0.8396\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 173us/step - loss: 0.6534 - accuracy: 0.7939\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.5902 - accuracy: 0.7956\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.5382 - accuracy: 0.8049\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4964 - accuracy: 0.8236\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4670 - accuracy: 0.8253\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4488 - accuracy: 0.8267\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4372 - accuracy: 0.8290\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4304 - accuracy: 0.8286\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4251 - accuracy: 0.8307\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4209 - accuracy: 0.8314\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4163 - accuracy: 0.8317\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4103 - accuracy: 0.8347\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4034 - accuracy: 0.8349\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3964 - accuracy: 0.8372\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3898 - accuracy: 0.8399\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3827 - accuracy: 0.8438\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3765 - accuracy: 0.8481\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3716 - accuracy: 0.8475\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3672 - accuracy: 0.8500\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3640 - accuracy: 0.8519\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3610 - accuracy: 0.8515\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3583 - accuracy: 0.8540\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.3560 - accuracy: 0.8558\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3539 - accuracy: 0.8554\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3524 - accuracy: 0.8542\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3508 - accuracy: 0.8572\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3498 - accuracy: 0.8585\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3490 - accuracy: 0.8564\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.3476 - accuracy: 0.8590\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 156us/step - loss: 0.3466 - accuracy: 0.8578\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3457 - accuracy: 0.8567\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3451 - accuracy: 0.8576\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3440 - accuracy: 0.8587\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3437 - accuracy: 0.8575\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3422 - accuracy: 0.8604\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3424 - accuracy: 0.8592\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3422 - accuracy: 0.8578\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3413 - accuracy: 0.8572\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3413 - accuracy: 0.8582\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3410 - accuracy: 0.8567\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3401 - accuracy: 0.8593\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3399 - accuracy: 0.8582\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3393 - accuracy: 0.8593\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.3398 - accuracy: 0.8589\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3397 - accuracy: 0.8585\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3392 - accuracy: 0.8611\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3380 - accuracy: 0.8606\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3388 - accuracy: 0.8592\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3388 - accuracy: 0.8603\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.3382 - accuracy: 0.8604\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3387 - accuracy: 0.8604\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3381 - accuracy: 0.8597\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3373 - accuracy: 0.8606\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3383 - accuracy: 0.8574\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3379 - accuracy: 0.8606\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3380 - accuracy: 0.8601\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3380 - accuracy: 0.8582\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3373 - accuracy: 0.8601\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3376 - accuracy: 0.8608\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3373 - accuracy: 0.8606\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3379 - accuracy: 0.8582\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3373 - accuracy: 0.8615\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3376 - accuracy: 0.8589\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3373 - accuracy: 0.8610\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3372 - accuracy: 0.8612\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3368 - accuracy: 0.8603\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3377 - accuracy: 0.8593\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3368 - accuracy: 0.8597\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3369 - accuracy: 0.8611\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3372 - accuracy: 0.8604\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3369 - accuracy: 0.8592\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3371 - accuracy: 0.8593\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3367 - accuracy: 0.8594\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3373 - accuracy: 0.8615\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3365 - accuracy: 0.8606\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3360 - accuracy: 0.8611\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3367 - accuracy: 0.8606\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3369 - accuracy: 0.8615\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3361 - accuracy: 0.8624\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3364 - accuracy: 0.8608\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3361 - accuracy: 0.8590\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3370 - accuracy: 0.8600\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3366 - accuracy: 0.8597\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3361 - accuracy: 0.8622\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3363 - accuracy: 0.8599\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3362 - accuracy: 0.8614\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3359 - accuracy: 0.8629\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3361 - accuracy: 0.8607\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3363 - accuracy: 0.8606\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3365 - accuracy: 0.8599\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3361 - accuracy: 0.8589\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3364 - accuracy: 0.8594\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3361 - accuracy: 0.8593\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.3365 - accuracy: 0.8606\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3357 - accuracy: 0.8586\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3363 - accuracy: 0.8628\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3359 - accuracy: 0.8599\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3355 - accuracy: 0.8615\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3357 - accuracy: 0.8617\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3354 - accuracy: 0.8608\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 193us/step - loss: 0.5739 - accuracy: 0.7962\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4401 - accuracy: 0.7975\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4296 - accuracy: 0.7975\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4251 - accuracy: 0.7975\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4217 - accuracy: 0.7975\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4179 - accuracy: 0.8046\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4153 - accuracy: 0.8228\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4137 - accuracy: 0.8272\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4124 - accuracy: 0.8299\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4111 - accuracy: 0.8303\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4099 - accuracy: 0.8314\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4088 - accuracy: 0.8329\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4077 - accuracy: 0.8319\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4074 - accuracy: 0.8349\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4061 - accuracy: 0.8347\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4057 - accuracy: 0.8357\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4052 - accuracy: 0.8358\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4049 - accuracy: 0.8360\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4042 - accuracy: 0.8354\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4041 - accuracy: 0.8361\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4036 - accuracy: 0.8349\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4028 - accuracy: 0.8358\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4029 - accuracy: 0.8368\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4026 - accuracy: 0.8361\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4020 - accuracy: 0.8368\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4019 - accuracy: 0.8360\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4017 - accuracy: 0.8360\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4015 - accuracy: 0.8353\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4014 - accuracy: 0.8357\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4011 - accuracy: 0.8360\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4012 - accuracy: 0.8360\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4009 - accuracy: 0.8364\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4008 - accuracy: 0.8354\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4000 - accuracy: 0.8374\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4000 - accuracy: 0.8351\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4000 - accuracy: 0.8347\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4000 - accuracy: 0.8358\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3998 - accuracy: 0.8357\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3998 - accuracy: 0.8351\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3996 - accuracy: 0.8353\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3994 - accuracy: 0.8365\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3993 - accuracy: 0.8354\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3991 - accuracy: 0.8357\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3994 - accuracy: 0.8367\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3989 - accuracy: 0.8363\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3987 - accuracy: 0.8360\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3984 - accuracy: 0.8385\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3990 - accuracy: 0.8376\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3986 - accuracy: 0.8351\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3987 - accuracy: 0.8368\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3982 - accuracy: 0.8372\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.3983 - accuracy: 0.8379\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.3984 - accuracy: 0.8344\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3980 - accuracy: 0.8376\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3978 - accuracy: 0.8363\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3979 - accuracy: 0.8369\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3980 - accuracy: 0.8381\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3975 - accuracy: 0.8378\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3978 - accuracy: 0.8363\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3977 - accuracy: 0.8372\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3976 - accuracy: 0.8379\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3975 - accuracy: 0.8383\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3972 - accuracy: 0.8381\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3972 - accuracy: 0.8349\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3975 - accuracy: 0.8376\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3973 - accuracy: 0.8381\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3971 - accuracy: 0.8363\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3972 - accuracy: 0.8363\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3972 - accuracy: 0.8379\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3971 - accuracy: 0.8385\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3970 - accuracy: 0.8360\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3969 - accuracy: 0.8375\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3971 - accuracy: 0.8390\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3967 - accuracy: 0.8374\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3971 - accuracy: 0.8367\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3969 - accuracy: 0.8375\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3969 - accuracy: 0.8376\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3969 - accuracy: 0.8367\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3967 - accuracy: 0.8372\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3966 - accuracy: 0.8389\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3969 - accuracy: 0.8372\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3965 - accuracy: 0.8376\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3969 - accuracy: 0.8367\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3967 - accuracy: 0.8388\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3963 - accuracy: 0.8379\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3963 - accuracy: 0.8388\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3967 - accuracy: 0.8369\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3965 - accuracy: 0.8358\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3967 - accuracy: 0.8386\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3962 - accuracy: 0.8375\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3965 - accuracy: 0.8371\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3965 - accuracy: 0.8376\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3961 - accuracy: 0.8365\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3960 - accuracy: 0.8371\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3962 - accuracy: 0.8393\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3962 - accuracy: 0.8371\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3963 - accuracy: 0.8385\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3962 - accuracy: 0.8372\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3963 - accuracy: 0.8376\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3964 - accuracy: 0.8379\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 170us/step - loss: 0.5742 - accuracy: 0.7931\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4461 - accuracy: 0.7937\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4366 - accuracy: 0.7937\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4335 - accuracy: 0.7937\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4316 - accuracy: 0.7937\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4293 - accuracy: 0.7937\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4266 - accuracy: 0.7937\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4243 - accuracy: 0.8092\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4225 - accuracy: 0.8183\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4213 - accuracy: 0.8218\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4200 - accuracy: 0.8222\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4188 - accuracy: 0.8251\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4174 - accuracy: 0.8276\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4169 - accuracy: 0.8279\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4157 - accuracy: 0.8289\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4152 - accuracy: 0.8282\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4142 - accuracy: 0.8319\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4140 - accuracy: 0.8307\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4134 - accuracy: 0.8319\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4127 - accuracy: 0.8325\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4122 - accuracy: 0.8339\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4116 - accuracy: 0.8338\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4115 - accuracy: 0.8324\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4110 - accuracy: 0.8336\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4109 - accuracy: 0.8342\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4106 - accuracy: 0.8329\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4103 - accuracy: 0.8336\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4098 - accuracy: 0.8342\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4097 - accuracy: 0.8329\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4093 - accuracy: 0.8319\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4094 - accuracy: 0.8326\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4091 - accuracy: 0.8338\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4087 - accuracy: 0.8339\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4086 - accuracy: 0.8326\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4084 - accuracy: 0.8325\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4083 - accuracy: 0.8325\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4082 - accuracy: 0.8325\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4075 - accuracy: 0.8329\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4077 - accuracy: 0.8326\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4077 - accuracy: 0.8328\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4071 - accuracy: 0.8322\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4073 - accuracy: 0.8329\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4074 - accuracy: 0.8331\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4068 - accuracy: 0.8335\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4069 - accuracy: 0.8322\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4066 - accuracy: 0.8326\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4066 - accuracy: 0.8329\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4064 - accuracy: 0.8340\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4062 - accuracy: 0.8340\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4063 - accuracy: 0.8332\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4061 - accuracy: 0.8328\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4060 - accuracy: 0.8329\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4059 - accuracy: 0.8342\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4057 - accuracy: 0.8340\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4054 - accuracy: 0.8329\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4057 - accuracy: 0.8314\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.4052 - accuracy: 0.8328\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4052 - accuracy: 0.8332\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4052 - accuracy: 0.8339\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4053 - accuracy: 0.8329\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4050 - accuracy: 0.8340\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 157us/step - loss: 0.4050 - accuracy: 0.8317\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 152us/step - loss: 0.4050 - accuracy: 0.8325\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4048 - accuracy: 0.8333\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4048 - accuracy: 0.8335\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4046 - accuracy: 0.8338\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4047 - accuracy: 0.8319\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4043 - accuracy: 0.8322\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4045 - accuracy: 0.8332\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4045 - accuracy: 0.8326\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4042 - accuracy: 0.8333\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4044 - accuracy: 0.8338\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 169us/step - loss: 0.4041 - accuracy: 0.8336\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 160us/step - loss: 0.4038 - accuracy: 0.8335\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4040 - accuracy: 0.8325\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4037 - accuracy: 0.8328\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4039 - accuracy: 0.8336\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4041 - accuracy: 0.8338\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4037 - accuracy: 0.8339\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4037 - accuracy: 0.8347\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4037 - accuracy: 0.8342\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4035 - accuracy: 0.8333\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4038 - accuracy: 0.8340\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4036 - accuracy: 0.8338\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4032 - accuracy: 0.8347\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4035 - accuracy: 0.8324\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4029 - accuracy: 0.8342\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4031 - accuracy: 0.8332\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4031 - accuracy: 0.8342\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4032 - accuracy: 0.8317\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4033 - accuracy: 0.8332\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4032 - accuracy: 0.8356\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4032 - accuracy: 0.8336\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4033 - accuracy: 0.8340\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4032 - accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4031 - accuracy: 0.8339\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4026 - accuracy: 0.8329\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4028 - accuracy: 0.8319\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4027 - accuracy: 0.8349\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4024 - accuracy: 0.8338\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 207us/step - loss: 0.6276 - accuracy: 0.7926\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4822 - accuracy: 0.7944\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4365 - accuracy: 0.7944\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4262 - accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4205 - accuracy: 0.8210\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4160 - accuracy: 0.8221\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4117 - accuracy: 0.8242\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4075 - accuracy: 0.8247\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4037 - accuracy: 0.8265\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4000 - accuracy: 0.8264\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3965 - accuracy: 0.8263\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3932 - accuracy: 0.8278\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3894 - accuracy: 0.8292\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3855 - accuracy: 0.8279\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3826 - accuracy: 0.8310\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3791 - accuracy: 0.8310\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3766 - accuracy: 0.8307\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3738 - accuracy: 0.8346\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3725 - accuracy: 0.8442\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3702 - accuracy: 0.8464\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3683 - accuracy: 0.8475\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3663 - accuracy: 0.8483\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3648 - accuracy: 0.8500\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3638 - accuracy: 0.8510\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3613 - accuracy: 0.8514\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3605 - accuracy: 0.8521\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3595 - accuracy: 0.8524\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3585 - accuracy: 0.8522\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3570 - accuracy: 0.8544\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3569 - accuracy: 0.8533\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3556 - accuracy: 0.8526\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3545 - accuracy: 0.8554\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3542 - accuracy: 0.8560\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3528 - accuracy: 0.8561\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3532 - accuracy: 0.8546\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3523 - accuracy: 0.8558\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3520 - accuracy: 0.8561\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3509 - accuracy: 0.8553\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3496 - accuracy: 0.8565\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3504 - accuracy: 0.8575\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3499 - accuracy: 0.8586\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3497 - accuracy: 0.8582\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3491 - accuracy: 0.8593\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3486 - accuracy: 0.8582\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3482 - accuracy: 0.8569\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3482 - accuracy: 0.8585\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3475 - accuracy: 0.8569\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3474 - accuracy: 0.8612\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3471 - accuracy: 0.8579\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3464 - accuracy: 0.8586\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3467 - accuracy: 0.8590\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3458 - accuracy: 0.8589\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3450 - accuracy: 0.8590\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3444 - accuracy: 0.8592\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3439 - accuracy: 0.8587\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3434 - accuracy: 0.8622\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3435 - accuracy: 0.8594\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3432 - accuracy: 0.8593\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3431 - accuracy: 0.8604\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3424 - accuracy: 0.8610\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3424 - accuracy: 0.8615\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3420 - accuracy: 0.8601\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3420 - accuracy: 0.8610\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3412 - accuracy: 0.8604\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3420 - accuracy: 0.8600\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3418 - accuracy: 0.8628\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3409 - accuracy: 0.8594\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3408 - accuracy: 0.8612\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3412 - accuracy: 0.8586\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3414 - accuracy: 0.8617\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3402 - accuracy: 0.8610\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3407 - accuracy: 0.8617\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3407 - accuracy: 0.8614\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3401 - accuracy: 0.8599\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3408 - accuracy: 0.8603\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3402 - accuracy: 0.8599\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3401 - accuracy: 0.8615\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3402 - accuracy: 0.8607\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3398 - accuracy: 0.8619\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3396 - accuracy: 0.8615\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3399 - accuracy: 0.8593\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3392 - accuracy: 0.8622\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3394 - accuracy: 0.8617\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3387 - accuracy: 0.8646\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3388 - accuracy: 0.8608\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3396 - accuracy: 0.8612\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3392 - accuracy: 0.8625\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3395 - accuracy: 0.8606\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3389 - accuracy: 0.8607\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3386 - accuracy: 0.8603\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3387 - accuracy: 0.8643\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.3380 - accuracy: 0.8637\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3386 - accuracy: 0.8615\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3387 - accuracy: 0.8622\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.3390 - accuracy: 0.8626\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3385 - accuracy: 0.8615\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3384 - accuracy: 0.8629\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3382 - accuracy: 0.8639\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3387 - accuracy: 0.8615\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3384 - accuracy: 0.8611\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 179us/step - loss: 0.5694 - accuracy: 0.7972\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 156us/step - loss: 0.4412 - accuracy: 0.7969\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 153us/step - loss: 0.4311 - accuracy: 0.7969\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4272 - accuracy: 0.7969\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4245 - accuracy: 0.7969\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4216 - accuracy: 0.7969\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4192 - accuracy: 0.8060\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4174 - accuracy: 0.8190\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4162 - accuracy: 0.8256\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4150 - accuracy: 0.8286\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4139 - accuracy: 0.8285\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4132 - accuracy: 0.8311\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4121 - accuracy: 0.83061s - los\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4119 - accuracy: 0.8322\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4108 - accuracy: 0.8322\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4103 - accuracy: 0.8336\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4097 - accuracy: 0.8336\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4092 - accuracy: 0.8329\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4087 - accuracy: 0.8333\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4082 - accuracy: 0.8349\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4077 - accuracy: 0.8343\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4071 - accuracy: 0.8358\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4071 - accuracy: 0.8351\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4065 - accuracy: 0.8353\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4062 - accuracy: 0.8349\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4060 - accuracy: 0.8349\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4055 - accuracy: 0.8354\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4048 - accuracy: 0.8350\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4055 - accuracy: 0.8357\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4049 - accuracy: 0.8360\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4046 - accuracy: 0.8363\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4046 - accuracy: 0.8363\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4040 - accuracy: 0.8351\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4039 - accuracy: 0.8354\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4039 - accuracy: 0.8364\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4034 - accuracy: 0.8351\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4036 - accuracy: 0.8357\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4034 - accuracy: 0.8351\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4032 - accuracy: 0.8357\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4028 - accuracy: 0.8350\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4030 - accuracy: 0.8346\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4029 - accuracy: 0.8350\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4027 - accuracy: 0.8347\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4021 - accuracy: 0.8347\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4026 - accuracy: 0.8346\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4026 - accuracy: 0.8344\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4023 - accuracy: 0.8346\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4025 - accuracy: 0.8357\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4022 - accuracy: 0.8365\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4023 - accuracy: 0.8349\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4020 - accuracy: 0.8350\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4019 - accuracy: 0.8357\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4017 - accuracy: 0.8356\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4017 - accuracy: 0.8363\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4016 - accuracy: 0.8376\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4015 - accuracy: 0.8363\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4013 - accuracy: 0.8360\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4016 - accuracy: 0.8353\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4016 - accuracy: 0.8357\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4011 - accuracy: 0.8356\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4012 - accuracy: 0.8349\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4013 - accuracy: 0.8361\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4014 - accuracy: 0.8356\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4012 - accuracy: 0.8350\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4011 - accuracy: 0.8356\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4010 - accuracy: 0.8363\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4013 - accuracy: 0.8344\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4012 - accuracy: 0.8350\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4007 - accuracy: 0.8351\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4010 - accuracy: 0.8358\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4012 - accuracy: 0.8372\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4010 - accuracy: 0.8354\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4009 - accuracy: 0.8351\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4006 - accuracy: 0.8351\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4010 - accuracy: 0.8358\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4008 - accuracy: 0.8361\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4006 - accuracy: 0.8358\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4008 - accuracy: 0.8364\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4008 - accuracy: 0.8361\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4007 - accuracy: 0.8363\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4009 - accuracy: 0.8365\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4008 - accuracy: 0.8361\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4006 - accuracy: 0.8344\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4005 - accuracy: 0.8356\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4007 - accuracy: 0.8343\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4007 - accuracy: 0.8356\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4005 - accuracy: 0.8354\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4005 - accuracy: 0.8356\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4004 - accuracy: 0.8351\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4001 - accuracy: 0.8361\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4005 - accuracy: 0.8357\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4003 - accuracy: 0.8354\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 103us/step - loss: 0.4005 - accuracy: 0.8361\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4005 - accuracy: 0.8361\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 105us/step - loss: 0.4005 - accuracy: 0.8368\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4004 - accuracy: 0.8361\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4001 - accuracy: 0.8349\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4004 - accuracy: 0.8353\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4004 - accuracy: 0.8349\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 104us/step - loss: 0.4004 - accuracy: 0.8367\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.5958 - accuracy: 0.7960\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4455 - accuracy: 0.7962\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4266 - accuracy: 0.7962\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4207 - accuracy: 0.8044\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.4143 - accuracy: 0.8253\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4086 - accuracy: 0.8251\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4020 - accuracy: 0.8292\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3961 - accuracy: 0.8293\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3909 - accuracy: 0.8300\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3863 - accuracy: 0.8328\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3826 - accuracy: 0.8340\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3784 - accuracy: 0.8336\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3755 - accuracy: 0.8335\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3726 - accuracy: 0.8406\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.3699 - accuracy: 0.8464\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3676 - accuracy: 0.8503\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3658 - accuracy: 0.8501\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3632 - accuracy: 0.8508\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3624 - accuracy: 0.8515\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3611 - accuracy: 0.8521\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3598 - accuracy: 0.8546\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3584 - accuracy: 0.8544\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3573 - accuracy: 0.8537\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3562 - accuracy: 0.8558\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3552 - accuracy: 0.8556\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3547 - accuracy: 0.8542\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3528 - accuracy: 0.8590\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3527 - accuracy: 0.8540\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3520 - accuracy: 0.8569\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3510 - accuracy: 0.8564\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3511 - accuracy: 0.8571\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3503 - accuracy: 0.8554\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3500 - accuracy: 0.8574\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 112us/step - loss: 0.3489 - accuracy: 0.8568\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3488 - accuracy: 0.8582\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3482 - accuracy: 0.8557\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3476 - accuracy: 0.8587\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3472 - accuracy: 0.8576\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3473 - accuracy: 0.8585\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3462 - accuracy: 0.8574\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3462 - accuracy: 0.8592\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3458 - accuracy: 0.8568\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.3454 - accuracy: 0.8561\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3449 - accuracy: 0.8583\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3453 - accuracy: 0.8585\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3448 - accuracy: 0.8600\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3450 - accuracy: 0.8575\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3443 - accuracy: 0.8600\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3438 - accuracy: 0.8599\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3435 - accuracy: 0.8575\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3429 - accuracy: 0.8582\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3436 - accuracy: 0.8599\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3430 - accuracy: 0.8599\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3430 - accuracy: 0.8606\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3433 - accuracy: 0.8582\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 165us/step - loss: 0.3423 - accuracy: 0.8603\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3416 - accuracy: 0.8596\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3424 - accuracy: 0.8608\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3420 - accuracy: 0.8604\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3415 - accuracy: 0.8607\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3416 - accuracy: 0.8587\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3407 - accuracy: 0.8632\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3400 - accuracy: 0.8608\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3408 - accuracy: 0.8610\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3409 - accuracy: 0.8611\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3407 - accuracy: 0.8626\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3392 - accuracy: 0.8587\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3401 - accuracy: 0.8636\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3398 - accuracy: 0.8589\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3394 - accuracy: 0.8633\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3395 - accuracy: 0.8626\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3392 - accuracy: 0.8612\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3376 - accuracy: 0.8618\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3382 - accuracy: 0.8621\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3377 - accuracy: 0.8632\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3377 - accuracy: 0.8617\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3371 - accuracy: 0.8622\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3376 - accuracy: 0.8626\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3364 - accuracy: 0.8626\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3368 - accuracy: 0.8604\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3364 - accuracy: 0.8622\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3365 - accuracy: 0.8608\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3360 - accuracy: 0.8621\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3359 - accuracy: 0.8614\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3361 - accuracy: 0.8621\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3361 - accuracy: 0.8619\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.3357 - accuracy: 0.8621\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3351 - accuracy: 0.8622\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3353 - accuracy: 0.8629\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3353 - accuracy: 0.8617\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3359 - accuracy: 0.8611\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3357 - accuracy: 0.8587\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3356 - accuracy: 0.8625\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3345 - accuracy: 0.8626\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3355 - accuracy: 0.8603\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3346 - accuracy: 0.8640\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3345 - accuracy: 0.8618\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3350 - accuracy: 0.8599\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3345 - accuracy: 0.8615\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.3347 - accuracy: 0.8628\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 2s 216us/step - loss: 0.5713 - accuracy: 0.7939\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4396 - accuracy: 0.7957\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4304 - accuracy: 0.7957\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.4262 - accuracy: 0.7957\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4224 - accuracy: 0.7957\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 163us/step - loss: 0.4192 - accuracy: 0.7957\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.4162 - accuracy: 0.8139\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 175us/step - loss: 0.4144 - accuracy: 0.8257\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.4131 - accuracy: 0.8283\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.4118 - accuracy: 0.8317\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.4106 - accuracy: 0.8304\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4098 - accuracy: 0.8324\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4088 - accuracy: 0.8332\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.4082 - accuracy: 0.8363\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4072 - accuracy: 0.8351\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4066 - accuracy: 0.8350\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4061 - accuracy: 0.8354\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4056 - accuracy: 0.8353\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4051 - accuracy: 0.8353\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4044 - accuracy: 0.8353\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4039 - accuracy: 0.8363\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4035 - accuracy: 0.8374\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4032 - accuracy: 0.8358\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4024 - accuracy: 0.8369\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4026 - accuracy: 0.8375\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4020 - accuracy: 0.8364\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4021 - accuracy: 0.8367\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4018 - accuracy: 0.8372\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4012 - accuracy: 0.8379\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4013 - accuracy: 0.8368\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4009 - accuracy: 0.8361\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4009 - accuracy: 0.8356\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4009 - accuracy: 0.8378\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4005 - accuracy: 0.8372\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4003 - accuracy: 0.8372\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.4001 - accuracy: 0.8372\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3999 - accuracy: 0.8371\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3999 - accuracy: 0.8365\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 111us/step - loss: 0.3996 - accuracy: 0.8371\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3994 - accuracy: 0.8369\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.3992 - accuracy: 0.8372\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3992 - accuracy: 0.8371\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3992 - accuracy: 0.8350\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3992 - accuracy: 0.8376\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3988 - accuracy: 0.8371\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3991 - accuracy: 0.8365\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3989 - accuracy: 0.8369\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3988 - accuracy: 0.8354\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3988 - accuracy: 0.8356\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3987 - accuracy: 0.8364\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3982 - accuracy: 0.8376\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3985 - accuracy: 0.8372\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.3980 - accuracy: 0.8354\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3985 - accuracy: 0.8371\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3983 - accuracy: 0.8358\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3981 - accuracy: 0.8365\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3979 - accuracy: 0.8363\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3981 - accuracy: 0.8368\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3980 - accuracy: 0.8369\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 110us/step - loss: 0.3974 - accuracy: 0.8367\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3978 - accuracy: 0.8360\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3977 - accuracy: 0.8375\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3976 - accuracy: 0.8381\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3976 - accuracy: 0.8365\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.3976 - accuracy: 0.8368\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3973 - accuracy: 0.8379\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 120us/step - loss: 0.3978 - accuracy: 0.8361\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3972 - accuracy: 0.8374\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3972 - accuracy: 0.8365\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3975 - accuracy: 0.8365\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3971 - accuracy: 0.8369\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3974 - accuracy: 0.8363\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3973 - accuracy: 0.8381\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3970 - accuracy: 0.8383\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3972 - accuracy: 0.8365\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.3968 - accuracy: 0.8385\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3972 - accuracy: 0.8374\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3971 - accuracy: 0.8381\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.3969 - accuracy: 0.8365\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3973 - accuracy: 0.8364\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.3969 - accuracy: 0.8372\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.3972 - accuracy: 0.8372\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3971 - accuracy: 0.8368\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3968 - accuracy: 0.8378\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3971 - accuracy: 0.8369\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3968 - accuracy: 0.8372\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3968 - accuracy: 0.8375\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3968 - accuracy: 0.8367\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3967 - accuracy: 0.8369\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3967 - accuracy: 0.8381\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3969 - accuracy: 0.8372\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3967 - accuracy: 0.8385\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3969 - accuracy: 0.8372\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3965 - accuracy: 0.8369\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3965 - accuracy: 0.8374\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3962 - accuracy: 0.8367\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3968 - accuracy: 0.8365\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3965 - accuracy: 0.8376\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3966 - accuracy: 0.8367\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3966 - accuracy: 0.8371\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 181us/step - loss: 0.5679 - accuracy: 0.7953\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4426 - accuracy: 0.7961\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4328 - accuracy: 0.7961\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4293 - accuracy: 0.7961\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4260 - accuracy: 0.7961\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4236 - accuracy: 0.7961\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4208 - accuracy: 0.8133\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4196 - accuracy: 0.8215\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4181 - accuracy: 0.8250\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4167 - accuracy: 0.8278\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4160 - accuracy: 0.8296\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4146 - accuracy: 0.8296\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4142 - accuracy: 0.8311\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4134 - accuracy: 0.8329\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4130 - accuracy: 0.8326\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4122 - accuracy: 0.8328\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4119 - accuracy: 0.8332\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4112 - accuracy: 0.8338\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4109 - accuracy: 0.8342\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4105 - accuracy: 0.8347\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4100 - accuracy: 0.8344\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4098 - accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4094 - accuracy: 0.8333\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4093 - accuracy: 0.8344\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4091 - accuracy: 0.8343\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4086 - accuracy: 0.8343\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4082 - accuracy: 0.8346\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4082 - accuracy: 0.8363\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4080 - accuracy: 0.8347\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4077 - accuracy: 0.8361\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4075 - accuracy: 0.8336\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4072 - accuracy: 0.8344\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4072 - accuracy: 0.8365\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4071 - accuracy: 0.8360\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4070 - accuracy: 0.8353\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4067 - accuracy: 0.8342\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4063 - accuracy: 0.8346\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4066 - accuracy: 0.8342\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4064 - accuracy: 0.8346\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4060 - accuracy: 0.8357\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4059 - accuracy: 0.8358\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4053 - accuracy: 0.8344\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4056 - accuracy: 0.8351\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4054 - accuracy: 0.8333\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4051 - accuracy: 0.8343\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4052 - accuracy: 0.8349\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4050 - accuracy: 0.8338\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4048 - accuracy: 0.8351\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4049 - accuracy: 0.8347\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4047 - accuracy: 0.8357\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4047 - accuracy: 0.8344\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4042 - accuracy: 0.8331\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4046 - accuracy: 0.8357\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4045 - accuracy: 0.8353\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4044 - accuracy: 0.8363\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4041 - accuracy: 0.8364\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4042 - accuracy: 0.8351\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4043 - accuracy: 0.8339\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4041 - accuracy: 0.8343\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4040 - accuracy: 0.8361\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4038 - accuracy: 0.8346\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4037 - accuracy: 0.8343\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4039 - accuracy: 0.8346\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4036 - accuracy: 0.8344\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4038 - accuracy: 0.8356\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4034 - accuracy: 0.8340\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4038 - accuracy: 0.8351\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4032 - accuracy: 0.8357\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4035 - accuracy: 0.8351\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4036 - accuracy: 0.8340\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4031 - accuracy: 0.8333\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4030 - accuracy: 0.8343\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4034 - accuracy: 0.83580s\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4029 - accuracy: 0.8338\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4034 - accuracy: 0.8346\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4032 - accuracy: 0.8356\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4030 - accuracy: 0.8357\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4034 - accuracy: 0.8350\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4031 - accuracy: 0.8339\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4030 - accuracy: 0.8343\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4034 - accuracy: 0.8350\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 106us/step - loss: 0.4031 - accuracy: 0.8360\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4025 - accuracy: 0.8344\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 107us/step - loss: 0.4030 - accuracy: 0.8347\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4030 - accuracy: 0.8367\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4031 - accuracy: 0.8336\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 108us/step - loss: 0.4027 - accuracy: 0.8338\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4028 - accuracy: 0.8365\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4028 - accuracy: 0.8361\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4028 - accuracy: 0.8343\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4029 - accuracy: 0.8343\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4028 - accuracy: 0.8356\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4026 - accuracy: 0.8357\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4026 - accuracy: 0.8354\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4025 - accuracy: 0.8351\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4026 - accuracy: 0.8360\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4024 - accuracy: 0.8360\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4026 - accuracy: 0.8364\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4029 - accuracy: 0.8354\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4022 - accuracy: 0.8342\n",
            "Epoch 1/500\n",
            "7200/7200 [==============================] - 2s 234us/step - loss: 0.5956 - accuracy: 0.7956\n",
            "Epoch 2/500\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4413 - accuracy: 0.7971\n",
            "Epoch 3/500\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4314 - accuracy: 0.7971\n",
            "Epoch 4/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4282 - accuracy: 0.7971\n",
            "Epoch 5/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4260 - accuracy: 0.7971\n",
            "Epoch 6/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4240 - accuracy: 0.7971\n",
            "Epoch 7/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4223 - accuracy: 0.7971\n",
            "Epoch 8/500\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4204 - accuracy: 0.7971\n",
            "Epoch 9/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4187 - accuracy: 0.8019\n",
            "Epoch 10/500\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4173 - accuracy: 0.8211\n",
            "Epoch 11/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4162 - accuracy: 0.8251\n",
            "Epoch 12/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4153 - accuracy: 0.8261\n",
            "Epoch 13/500\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.4142 - accuracy: 0.8285\n",
            "Epoch 14/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4133 - accuracy: 0.8296\n",
            "Epoch 15/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4126 - accuracy: 0.8308\n",
            "Epoch 16/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4119 - accuracy: 0.8311\n",
            "Epoch 17/500\n",
            "7200/7200 [==============================] - 1s 153us/step - loss: 0.4112 - accuracy: 0.8322\n",
            "Epoch 18/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4108 - accuracy: 0.8329\n",
            "Epoch 19/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4103 - accuracy: 0.8333\n",
            "Epoch 20/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4098 - accuracy: 0.8329\n",
            "Epoch 21/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4094 - accuracy: 0.8328\n",
            "Epoch 22/500\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.4089 - accuracy: 0.8332\n",
            "Epoch 23/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4084 - accuracy: 0.8346\n",
            "Epoch 24/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4081 - accuracy: 0.8326\n",
            "Epoch 25/500\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4075 - accuracy: 0.8343\n",
            "Epoch 26/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4074 - accuracy: 0.8353\n",
            "Epoch 27/500\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4071 - accuracy: 0.8360\n",
            "Epoch 28/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4068 - accuracy: 0.8349\n",
            "Epoch 29/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4064 - accuracy: 0.8342\n",
            "Epoch 30/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4061 - accuracy: 0.8364\n",
            "Epoch 31/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4058 - accuracy: 0.8357\n",
            "Epoch 32/500\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.4054 - accuracy: 0.8351\n",
            "Epoch 33/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4052 - accuracy: 0.8353\n",
            "Epoch 34/500\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4051 - accuracy: 0.8360\n",
            "Epoch 35/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4049 - accuracy: 0.8360\n",
            "Epoch 36/500\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4047 - accuracy: 0.8349\n",
            "Epoch 37/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4044 - accuracy: 0.8365\n",
            "Epoch 38/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4042 - accuracy: 0.8351\n",
            "Epoch 39/500\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4040 - accuracy: 0.8347\n",
            "Epoch 40/500\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4038 - accuracy: 0.8363\n",
            "Epoch 41/500\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4036 - accuracy: 0.8360\n",
            "Epoch 42/500\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4036 - accuracy: 0.8353\n",
            "Epoch 43/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4032 - accuracy: 0.8351\n",
            "Epoch 44/500\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4032 - accuracy: 0.8357\n",
            "Epoch 45/500\n",
            "7200/7200 [==============================] - 1s 118us/step - loss: 0.4029 - accuracy: 0.8365\n",
            "Epoch 46/500\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4030 - accuracy: 0.8363\n",
            "Epoch 47/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4027 - accuracy: 0.8363\n",
            "Epoch 48/500\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4026 - accuracy: 0.8353\n",
            "Epoch 49/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4025 - accuracy: 0.8351\n",
            "Epoch 50/500\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4023 - accuracy: 0.8351\n",
            "Epoch 51/500\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4021 - accuracy: 0.8363\n",
            "Epoch 52/500\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4019 - accuracy: 0.8365\n",
            "Epoch 53/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4020 - accuracy: 0.8356\n",
            "Epoch 54/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4016 - accuracy: 0.8354\n",
            "Epoch 55/500\n",
            "7200/7200 [==============================] - 1s 116us/step - loss: 0.4014 - accuracy: 0.8360\n",
            "Epoch 56/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4019 - accuracy: 0.8358\n",
            "Epoch 57/500\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4013 - accuracy: 0.8365\n",
            "Epoch 58/500\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4015 - accuracy: 0.8344\n",
            "Epoch 59/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4012 - accuracy: 0.8368\n",
            "Epoch 60/500\n",
            "7200/7200 [==============================] - 1s 117us/step - loss: 0.4012 - accuracy: 0.8351\n",
            "Epoch 61/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4013 - accuracy: 0.8356\n",
            "Epoch 62/500\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4011 - accuracy: 0.8363\n",
            "Epoch 63/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4010 - accuracy: 0.8343\n",
            "Epoch 64/500\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4012 - accuracy: 0.8343\n",
            "Epoch 65/500\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.4009 - accuracy: 0.8356\n",
            "Epoch 66/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4008 - accuracy: 0.8351\n",
            "Epoch 67/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4009 - accuracy: 0.8363\n",
            "Epoch 68/500\n",
            "7200/7200 [==============================] - 1s 114us/step - loss: 0.4008 - accuracy: 0.8351\n",
            "Epoch 69/500\n",
            "7200/7200 [==============================] - 1s 113us/step - loss: 0.4005 - accuracy: 0.8338\n",
            "Epoch 70/500\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4007 - accuracy: 0.8350\n",
            "Epoch 71/500\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4007 - accuracy: 0.8354\n",
            "Epoch 72/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4004 - accuracy: 0.8364\n",
            "Epoch 73/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4005 - accuracy: 0.8354\n",
            "Epoch 74/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4009 - accuracy: 0.8353\n",
            "Epoch 75/500\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4005 - accuracy: 0.8344\n",
            "Epoch 76/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4004 - accuracy: 0.8351\n",
            "Epoch 77/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4002 - accuracy: 0.8354\n",
            "Epoch 78/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4004 - accuracy: 0.8360\n",
            "Epoch 79/500\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4002 - accuracy: 0.8349\n",
            "Epoch 80/500\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4003 - accuracy: 0.8353\n",
            "Epoch 81/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4003 - accuracy: 0.8356\n",
            "Epoch 82/500\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4002 - accuracy: 0.8361\n",
            "Epoch 83/500\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4002 - accuracy: 0.8349\n",
            "Epoch 84/500\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4002 - accuracy: 0.8351\n",
            "Epoch 85/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4002 - accuracy: 0.8347\n",
            "Epoch 86/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4002 - accuracy: 0.8363\n",
            "Epoch 87/500\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4001 - accuracy: 0.8347\n",
            "Epoch 88/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4001 - accuracy: 0.8351\n",
            "Epoch 89/500\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.3999 - accuracy: 0.8363\n",
            "Epoch 90/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4002 - accuracy: 0.8350\n",
            "Epoch 91/500\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4001 - accuracy: 0.8353\n",
            "Epoch 92/500\n",
            "7200/7200 [==============================] - 1s 156us/step - loss: 0.4001 - accuracy: 0.8358\n",
            "Epoch 93/500\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3999 - accuracy: 0.8358\n",
            "Epoch 94/500\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4001 - accuracy: 0.8353\n",
            "Epoch 95/500\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3999 - accuracy: 0.8354\n",
            "Epoch 96/500\n",
            "5400/7200 [=====================>........] - ETA: 0s - loss: 0.4021 - accuracy: 0.8350"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUvK2N77ofuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B-e3v9Oofuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6FeS7eJoful",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}